{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "from pyro.nn import PyroSample, PyroModule\n",
    "from pyro.infer import SVI, Trace_ELBO, autoguide\n",
    "import torch\n",
    "from torch.nn.functional import softplus\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import anndata as ann\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "data = ann.read_h5ad(\"/mnt/storage/thien/projectdata/GSE194122_openproblems_neurips2021_cite_BMMC_processed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\\n,\n",
    "n_obs = 100\n",
    "n_features = 20\n",
    "n_factors = 5\n",
    "\n",
    "torch.manual_seed(2024)\n",
    "Z_in = torch.randn(n_obs, n_factors)\n",
    "W1_in = torch.randn(n_features, n_factors)\n",
    "W2_in = torch.randn(n_features, n_factors)\n",
    "\n",
    "X1 = torch.randn(n_obs, n_features)\n",
    "X2 = torch.randn(n_obs, n_features)\n",
    "\n",
    "# create observated values from the simulated factor and weight matrix with some random noise\\n,\n",
    "Y1 = torch.matmul(Z_in, W1_in.t()) + 0.2 * torch.randn(n_obs, n_features)\n",
    "Y2 = torch.matmul(Z_in, W2_in.t()) + 0.2 * torch.randn(n_obs, n_features)\n",
    "#print(Y.shape)\\n,\n",
    "#print(Y)\\n,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=20)\n",
    "W1 = pca1.fit_transform(X1)\n",
    "\n",
    "pca2 = PCA(n_components=20)\n",
    "W2 = pca2.fit_transform(X2)\n",
    "\n",
    "cca = CCA(n_components=20)\n",
    "W1_aligned, W2_aligned = cca.fit_transform(W1, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X1 = np.random.rand(100, 20)  # Modality 1\n",
    "X2 = np.random.rand(100, 30)  # Modality 2\n",
    "\n",
    "# Initialize shared and private components using PCA\n",
    "n, k = 100, 10  # Number of samples and latent dimensions\n",
    "pca1 = PCA(n_components=k)\n",
    "S1_init = pca1.fit_transform(X1)\n",
    "\n",
    "pca2 = PCA(n_components=k)\n",
    "S2_init = pca2.fit_transform(X2)\n",
    "\n",
    "# Initialize S as the average of the two PCA initializations\n",
    "S = (S1_init + S2_init) / 2\n",
    "U1 = X1 - S @ np.linalg.pinv(S.T @ S) @ S.T @ X1\n",
    "U2 = X2 - S @ np.linalg.pinv(S.T @ S) @ S.T @ X2\n",
    "\n",
    "# Define hyperparameters\n",
    "lambda_reg = 0.1\n",
    "num_iterations = 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X1 - S @ np.linalg.pinv(S.T @ S) @ S.T @ X1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FA(PyroModule):\n",
    "    def __init__(self, Y1, Y2, K):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y: Tensor (Samples x Features)\n",
    "            K: Number of Latent Factors\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # data\n",
    "        self.Y1 = Y1\n",
    "        self.Y2 = Y2\n",
    "        self.K = K\n",
    "        \n",
    "        self.num_samples = self.Y1.shape[0]\n",
    "        self.num_features1 = self.Y1.shape[1]\n",
    "        self.num_features2 = self.Y2.shape[1]\n",
    "        \n",
    "        self.sample_plate = pyro.plate(\"sample\", self.num_samples)\n",
    "        self.feature_plate1 = pyro.plate(\"feature1\", self.num_features1)\n",
    "        self.feature_plate2 = pyro.plate(\"feature2\", self.num_features2)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", self.K)\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        how to generate a matrix\n",
    "        \"\"\"\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate1:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W1 = pyro.sample(\"W1\", pyro.distributions.Normal(0., 1.))  \n",
    "\n",
    "            with self.feature_plate2:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W2 = pyro.sample(\"W2\", pyro.distributions.Normal(0., 1.))               \n",
    "                \n",
    "            with self.sample_plate:\n",
    "                # sample factor matrix with Normal prior distribution\n",
    "                Z = pyro.sample(\"Z\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        # estimate for Y\n",
    "        Y1_hat = torch.matmul(Z, W1.t())\n",
    "        Y2_hat = torch.matmul(Z, W2.t())\n",
    "        \n",
    "        with pyro.plate(\"feature1_\", self.Y1.shape[1]), pyro.plate(\"sample_\", self.Y1.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs_mask = torch.ones_like(self.Y1, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs_mask = torch.logical_not(torch.isnan(self.Y1))\n",
    "            with pyro.poutine.mask(mask=obs_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y1 = torch.nan_to_num(self.Y1, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale = pyro.sample(\"scale\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs1\", pyro.distributions.Normal(Y1_hat, scale), obs=self.Y1)\n",
    "\n",
    "\n",
    "        with pyro.plate(\"feature2_\", self.Y2.shape[1]), pyro.plate(\"sample2_\", self.Y2.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs_mask = torch.ones_like(self.Y2, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs_mask = torch.logical_not(torch.isnan(self.Y2))\n",
    "            with pyro.poutine.mask(mask=obs_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y2 = torch.nan_to_num(self.Y2, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale = pyro.sample(\"scale2\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs2\", pyro.distributions.Normal(Y2_hat, scale), obs=self.Y2)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # set training parameters\n",
    "        optimizer = pyro.optim.Adam({\"lr\": 0.02})\n",
    "        elbo = Trace_ELBO()\n",
    "        guide = autoguide.AutoDelta(self.model)\n",
    "        \n",
    "        # initialize stochastic variational inference\n",
    "        svi = SVI(\n",
    "            model = self.model,\n",
    "            guide = guide,\n",
    "            optim = optimizer,\n",
    "            loss = elbo\n",
    "        )\n",
    "        \n",
    "        num_iterations = 2000\n",
    "        train_loss = []\n",
    "        for j in range(num_iterations):\n",
    "            # calculate the loss and take a gradient step\n",
    "            loss = svi.step()\n",
    "\n",
    "            train_loss.append(loss/self.Y1.shape[0])              \n",
    "            if j % 200 == 0:\n",
    "                print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / self.Y1.shape[0]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Obtain maximum a posteriori estimates for W and Z\n",
    "        map_estimates = guide([Y1])\n",
    "        \n",
    "        return train_loss, map_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_trainX = torch.utils.data.DataLoader(PBMC_train.X.A, batch_size=128)\n",
    "PBMC_train, mask = create_mask(PBMC_train, gmt_path= \"reactomes.gmt\", add_nodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_validX = torch.utils.data.DataLoader(PBMC_valid.X.A, batch_size=128)\n",
    "\n",
    "def trainVEGA_with_valid(vae, data, val_data, epochs=100, beta = 0.0001, learning_rate = 0.001):\n",
    "    opt = torch.optim.Adam(vae.parameters(), lr = learning_rate, weight_decay = 5e-4)\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss_e = 0\n",
    "        valid_loss_e = 0\n",
    "        vae.train() #train mode\n",
    "\n",
    "        for x in data:\n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = vae(x)\n",
    "            loss = ((x - x_hat)**2).sum() + beta* vae.encoder.kl\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss_e += loss.to('cpu').detach().numpy()\n",
    "            vae.decoder.positive_weights() # we restrict the decoder to positive weights\n",
    "        train_losses.append(train_loss_e/(len(data)*128))\n",
    "\n",
    "        #### Here you should add the validation loop\n",
    "        vae.eval()\n",
    "        for x in val_data:\n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = vae(x)\n",
    "            loss = ((x - x_hat)**2).sum() + beta* vae.encoder.kl\n",
    "            valid_loss_e += loss.to('cpu').detach().numpy()\n",
    "        valid_losses.append(valid_loss_e/(len(val_data)*128))\n",
    "        \n",
    "        print(\"epoch: \", epoch, \" train_loss: \", train_loss_e/(len(data)*128))\n",
    "\n",
    "        #### print also the validation loss after each epoch!\n",
    "        print(\"epoch: \", epoch, \" valid_loss: \", valid_loss_e/(len(val_data)*128))\n",
    "    return vae, train_losses, valid_losses\n",
    "\n",
    "\n",
    "# model initialization and training\n",
    "vega = VEGA(latent_dims= mask.shape[1], input_dims = mask.shape[0], mask = mask.T, dropout = 0.3, z_dropout = 0.3).to(device)\n",
    "vega, train_losses, valid_losses = trainVEGA_with_valid(vega, PBMC_trainX, PBMC_validX, epochs = 50, beta = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "X3 = torch.cat((X1, X2), dim=0)\n",
    "Y3 = torch.cat((Y1, Y2), dim=0)\n",
    "dat = torch.cat((X3, Y3), dim=0)\n",
    "train_dataloader = DataLoader(dat[:(int(0.8*dat.shape[1]))], batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(dat[(int(0.8*dat.shape[1])):], batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FA(PyroModule):\n",
    "    def __init__(self, Y1, Y2, train_dataloader, K):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y: Tensor (Samples x Features)\n",
    "            K: Number of Latent Factors\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # data\n",
    "        self.Y1 = Y1\n",
    "        self.Y2 = Y2\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.K = K\n",
    "        \n",
    "        self.num_samples = self.Y1.shape[0]\n",
    "        self.num_features1 = self.Y1.shape[1]\n",
    "        self.num_features2 = self.Y2.shape[1]\n",
    "        \n",
    "        self.sample_plate = pyro.plate(\"sample\", self.num_samples)\n",
    "        self.feature_plate1 = pyro.plate(\"feature\", self.num_features1)\n",
    "        self.feature_plate2 = pyro.plate(\"feature\", self.num_features2)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", self.K)\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        how to generate a matrix\n",
    "        \"\"\"\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate1:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W1 = pyro.sample(\"W1\", pyro.distributions.Normal(0., 1.))  \n",
    "\n",
    "            with self.feature_plate1:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W2 = pyro.sample(\"W2\", pyro.distributions.Normal(0., 1.))               \n",
    "                \n",
    "            with self.sample_plate:\n",
    "                # sample factor matrix with Normal prior distribution\n",
    "                Z = pyro.sample(\"Z\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        # estimate for Y\n",
    "        Y1_hat = torch.matmul(Z, W1.t())\n",
    "        Y2_hat = torch.matmul(Z, W2.t())\n",
    "        \n",
    "        with pyro.plate(\"feature1_\", self.Y1.shape[1]), pyro.plate(\"sample_\", self.Y1.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs_mask = torch.ones_like(self.Y1, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs_mask = torch.logical_not(torch.isnan(self.Y1))\n",
    "            with pyro.poutine.mask(mask=obs_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y1 = torch.nan_to_num(self.Y1, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale = pyro.sample(\"scale\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs1\", pyro.distributions.Normal(Y1_hat, scale), obs=self.Y1)\n",
    "\n",
    "\n",
    "        with pyro.plate(\"feature2_\", self.Y2.shape[1]), pyro.plate(\"sample2_\", self.Y2.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs_mask = torch.ones_like(self.Y2, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs_mask = torch.logical_not(torch.isnan(self.Y2))\n",
    "            with pyro.poutine.mask(mask=obs_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y2 = torch.nan_to_num(self.Y2, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale = pyro.sample(\"scale2\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs2\", pyro.distributions.Normal(Y2_hat, scale), obs=self.Y2)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # set training parameters\n",
    "        optimizer = pyro.optim.Adam({\"lr\": 0.02})\n",
    "        elbo = Trace_ELBO()\n",
    "        guide = autoguide.AutoDelta(self.model)\n",
    "        \n",
    "        # initialize stochastic variational inference\n",
    "        svi = SVI(\n",
    "            model = self.model,\n",
    "            guide = guide,\n",
    "            optim = optimizer,\n",
    "            loss = elbo\n",
    "        )\n",
    "        \n",
    "        num_iterations = 2000\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        #for j in range(num_iterations):\n",
    "        for batchidx, (x, ) in enumerate(self.train_dataloader):\n",
    "            # calculate the loss and take a gradient step\n",
    "            loss = svi.step(batchidx)\n",
    "\n",
    "            train_loss.append(loss/self.Y1.shape[0])\n",
    "            #with torch.no_grad:\n",
    "            #    test_loss.append(elbo.loss(self.model, guide, test_data))\n",
    "            if j % 200 == 0:\n",
    "                print(\"[iteration %04d] loss: %.4f\" % (batchidx + 1, loss / self.Y1.shape[0]))\n",
    "        \n",
    "        # Obtain maximum a posteriori estimates for W and Z\n",
    "        map_estimates = guide(Y1)\n",
    "        \n",
    "        return train_loss, map_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 225.3263\n",
      "[iteration 0201] loss: 23.5264\n",
      "[iteration 0401] loss: 17.8712\n",
      "[iteration 0601] loss: 16.7027\n",
      "[iteration 0801] loss: 16.3810\n",
      "[iteration 1001] loss: 16.2827\n",
      "[iteration 1201] loss: 16.2464\n",
      "[iteration 1401] loss: 16.2281\n",
      "[iteration 1601] loss: 16.2239\n",
      "[iteration 1801] loss: 16.2226\n"
     ]
    }
   ],
   "source": [
    "FA_model = FA(Y1, Y2,5)\n",
    "losses, estimates = FA_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 9318.558555603027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 : loss = 8188.762435913086\n",
      "Step 200 : loss = 8140.568473815918\n",
      "Step 300 : loss = 8099.411827087402\n",
      "Step 400 : loss = 8090.755569458008\n",
      "Step 500 : loss = 8125.01838684082\n",
      "Step 600 : loss = 8119.451477050781\n",
      "Step 700 : loss = 8130.613334655762\n",
      "Step 800 : loss = 8129.570518493652\n",
      "Step 900 : loss = 8072.03630065918\n",
      "Step 1000 : loss = 8095.539978027344\n",
      "Step 1100 : loss = 8127.798934936523\n",
      "Step 1200 : loss = 8098.893905639648\n",
      "Step 1300 : loss = 8076.998802185059\n",
      "Step 1400 : loss = 8065.0046310424805\n",
      "Step 1500 : loss = 8054.4304122924805\n",
      "Step 1600 : loss = 8096.44970703125\n",
      "Step 1700 : loss = 8083.843765258789\n",
      "Step 1800 : loss = 8124.302635192871\n",
      "Step 1900 : loss = 8107.515960693359\n",
      "Step 2000 : loss = 8127.2685546875\n",
      "Step 2100 : loss = 8115.371719360352\n",
      "Step 2200 : loss = 8070.581451416016\n",
      "Step 2300 : loss = 8083.663627624512\n",
      "Step 2400 : loss = 8093.483543395996\n",
      "Step 2500 : loss = 8127.0180740356445\n",
      "Step 2600 : loss = 8084.9541015625\n",
      "Step 2700 : loss = 8084.7431640625\n",
      "Step 2800 : loss = 8090.177444458008\n",
      "Step 2900 : loss = 8120.57048034668\n",
      "Step 3000 : loss = 8110.682289123535\n",
      "Step 3100 : loss = 8123.991065979004\n",
      "Step 3200 : loss = 8097.127815246582\n",
      "Step 3300 : loss = 8078.724899291992\n",
      "Step 3400 : loss = 8114.382713317871\n",
      "Step 3500 : loss = 8097.508193969727\n",
      "Step 3600 : loss = 8054.692237854004\n",
      "Step 3700 : loss = 8097.085433959961\n",
      "Step 3800 : loss = 8094.738052368164\n",
      "Step 3900 : loss = 8074.087348937988\n",
      "Step 4000 : loss = 8136.3628005981445\n",
      "Step 4100 : loss = 8107.203201293945\n",
      "Step 4200 : loss = 8096.581588745117\n",
      "Step 4300 : loss = 8075.484878540039\n",
      "Step 4400 : loss = 8068.950790405273\n",
      "Step 4500 : loss = 8051.870445251465\n",
      "Step 4600 : loss = 8082.151390075684\n",
      "Step 4700 : loss = 8110.891204833984\n",
      "Step 4800 : loss = 8077.896286010742\n",
      "Step 4900 : loss = 8076.423599243164\n",
      "Shared components (S):\n",
      " [[ 7.76132643e-01  4.50856715e-01 -3.64668518e-01  1.84829131e-01\n",
      "   5.92754744e-02  3.00218791e-01  8.80146682e-01 -1.04356487e-03\n",
      "   3.22606444e-01  2.65274793e-02]\n",
      " [ 3.55848849e-01  1.81560189e-01  3.38087112e-01  7.15567946e-01\n",
      "   5.60277700e-01 -2.56074369e-01 -1.06974530e+00  1.83630198e-01\n",
      "  -1.34060860e-01 -2.06961110e-01]\n",
      " [ 1.71298131e-01  1.77349411e-02  2.64988989e-02  3.37529272e-01\n",
      "  -3.60436738e-01 -3.73576909e-01 -5.54997027e-02  2.75395870e-01\n",
      "   5.18992424e-01 -2.07446456e-01]\n",
      " [ 4.69754189e-01  5.10556936e-01  2.82661080e-01 -1.01464592e-01\n",
      "  -3.04540575e-01 -8.20059836e-01 -6.88282192e-01 -7.97781825e-01\n",
      "  -9.36822891e-02 -2.88148135e-01]\n",
      " [ 3.78603004e-02 -2.58167326e-01  4.62530375e-01  2.76554316e-01\n",
      "   2.94543505e-01  3.53956521e-01  3.06125224e-01  5.11345387e-01\n",
      "   5.46932757e-01  3.14509392e-01]\n",
      " [-1.79620475e-01 -2.10866958e-01 -8.18051755e-01  4.14085388e-01\n",
      "  -6.30815208e-01  5.31196773e-01  5.08328620e-03 -2.88558565e-03\n",
      "  -4.00738478e-01  4.56017047e-01]\n",
      " [-1.12990327e-01 -9.03095677e-02 -7.46677816e-02  2.90732980e-01\n",
      "   4.39867079e-01  4.00622413e-02  3.99485901e-02  6.52526557e-01\n",
      "   5.42555273e-01 -7.14264095e-01]\n",
      " [-3.09036463e-01  7.49937057e-01  2.61892021e-01  7.35685766e-01\n",
      "  -6.77952170e-01  5.50647140e-01  1.15288520e+00  6.65633440e-01\n",
      "  -1.23867907e-01  8.86358768e-02]\n",
      " [-2.07927197e-01  7.17834532e-01 -4.98995513e-01 -3.30275089e-01\n",
      "  -1.41518056e+00  1.58396944e-01  6.46050811e-01 -3.47306013e-01\n",
      "  -3.97915691e-01  3.88033628e-01]\n",
      " [-2.05934957e-01  3.14279616e-01 -1.42336950e-01  3.31950605e-01\n",
      "  -2.13235691e-02 -4.39962387e-01 -8.31265688e-01  4.01412010e-01\n",
      "   5.37318110e-01 -1.84159815e-01]\n",
      " [-4.34355617e-01 -1.19150245e+00 -1.20942926e+00 -2.28911355e-01\n",
      "  -1.48823276e-01  2.84326941e-01 -3.85508925e-01 -1.08499968e+00\n",
      "  -2.42178380e-01 -5.87844431e-01]\n",
      " [-2.45585844e-01  3.28203499e-01 -3.35959017e-01  4.72842813e-01\n",
      "  -1.42472878e-01 -1.12716591e+00 -7.36652017e-01  4.16656047e-01\n",
      "  -5.20870574e-02 -4.46906686e-01]\n",
      " [-3.76885802e-01 -4.68308032e-01  2.86380649e-01 -2.91877627e-01\n",
      "  -5.83379626e-01 -6.27416551e-01 -6.06969774e-01  7.07912266e-01\n",
      "   5.44635296e-01  6.63947880e-01]\n",
      " [-3.17651719e-01  6.12247586e-01  1.41679972e-01 -1.86670318e-01\n",
      "  -2.98137635e-01 -5.05435765e-01  1.98428944e-01  5.00389099e-01\n",
      "  -3.26106429e-01  4.97277915e-01]\n",
      " [ 6.93425357e-01 -4.15090518e-03 -4.32828039e-01  1.17281184e-01\n",
      "   2.65631706e-01  4.97555971e-01  3.78474265e-01 -7.27990091e-01\n",
      "  -8.00868273e-01 -2.95538843e-01]\n",
      " [-3.13853286e-02  2.67306924e-01 -5.10207340e-02 -2.67386019e-01\n",
      "   1.52933717e-01 -3.83486301e-01  4.76408511e-01  5.59274971e-01\n",
      "  -1.16172116e-02 -1.34449631e-01]\n",
      " [-2.21682474e-01  2.04013720e-01  7.49292374e-01 -2.90307462e-01\n",
      "   4.48629320e-01  5.83828092e-01 -3.57001334e-01 -1.05560958e+00\n",
      "  -6.54156327e-01 -5.43540865e-02]\n",
      " [-3.27124506e-01  6.33187413e-01  3.93312871e-01 -2.34058321e-01\n",
      "  -9.82089221e-01  6.72045425e-02  6.06003642e-01 -3.28757823e-01\n",
      "   7.27337480e-01  7.29459107e-01]\n",
      " [-6.92987144e-01 -3.82488251e-01 -3.94673944e-01 -5.17665386e-01\n",
      "   6.17499411e-01 -1.33619845e+00 -1.97130337e-01 -5.57745814e-01\n",
      "  -1.42421260e-01  5.99795222e-01]\n",
      " [ 7.24905312e-01 -1.10750949e+00  3.01076651e-01  7.13599026e-01\n",
      "  -1.08431958e-01 -5.50666273e-01  3.67169529e-01 -1.83335409e-01\n",
      "  -5.32782793e-01 -3.62038672e-01]\n",
      " [-5.25963545e-01 -4.01410282e-01 -4.90825146e-01 -1.24117827e+00\n",
      "   9.37263608e-01 -9.04090703e-02  5.97379170e-02  4.34674829e-01\n",
      "   1.15829468e-01  2.49945074e-01]\n",
      " [-3.91309038e-02  8.97642195e-01 -5.81721663e-01  4.94481236e-01\n",
      "  -2.93689705e-02 -2.48947889e-01 -3.63861442e-01  1.55054405e-01\n",
      "   1.52416378e-01  1.16635494e-01]\n",
      " [-2.59860098e-01 -2.04802155e-01  6.37290031e-02  4.51982141e-01\n",
      "   4.54881996e-01  8.41156065e-01 -6.51104093e-01  3.21893007e-01\n",
      "   4.10909206e-01  6.55972123e-01]\n",
      " [ 1.86960753e-02  4.66033459e-01  1.79145545e-01 -2.30003014e-01\n",
      "   4.06889170e-01  4.47414011e-01 -5.63777268e-01 -1.01624221e-01\n",
      "  -2.48786062e-01 -1.77072719e-01]\n",
      " [-5.54396868e-01 -1.07660927e-01  3.09434384e-01  6.92850888e-01\n",
      "   7.92246088e-02  1.47917435e-01  4.73478079e-01 -6.76409662e-01\n",
      "  -8.95245224e-02 -2.69283205e-01]\n",
      " [-3.59990895e-01 -2.68030494e-01 -9.35375869e-01 -8.20442513e-02\n",
      "   4.80976641e-01 -2.00729504e-01  6.63094163e-01  3.00258100e-01\n",
      "   2.21179128e-02 -3.71547759e-01]\n",
      " [ 3.11509907e-01 -5.00898302e-01 -5.48371255e-01  2.97466993e-01\n",
      "  -1.61915153e-01 -3.44972104e-01  1.69172391e-01 -4.15746868e-01\n",
      "  -1.65380999e-01  7.78358355e-02]\n",
      " [-1.97789714e-01  6.79132044e-01  8.33370462e-02 -6.71445504e-02\n",
      "   6.49549127e-01  6.65064380e-02  4.54128265e-01  1.15603797e-01\n",
      "   2.01263323e-01 -1.54256731e-01]\n",
      " [ 3.35031271e-01  9.04512346e-01  3.47431079e-02  9.13810790e-01\n",
      "   1.00262284e+00 -9.92873162e-02  6.46289229e-01 -8.37243140e-01\n",
      "   2.31525600e-01 -2.21510664e-01]\n",
      " [-3.32064591e-02 -6.25962436e-01  2.47088119e-01  3.17630470e-01\n",
      "  -6.25394166e-01 -2.31857494e-01 -5.04396595e-02  1.32605112e+00\n",
      "  -4.18553144e-01  6.29122034e-02]\n",
      " [-3.27531964e-01 -2.84502000e-01 -2.60612845e-01  6.34814948e-02\n",
      "  -9.89750400e-02 -1.33218086e+00 -3.35448086e-01  1.29896903e+00\n",
      "  -1.41203567e-01 -4.13953841e-01]\n",
      " [-1.35936522e+00  3.17816958e-02  6.24744333e-02  9.35613394e-01\n",
      "  -4.05231357e-01 -2.76949346e-01  6.04940772e-01 -2.30004758e-01\n",
      "   2.30920240e-01 -8.66004676e-02]\n",
      " [ 3.16021681e-01 -2.45077729e-01  6.80110902e-02 -4.48787540e-01\n",
      "   9.03170705e-02 -3.64083380e-01  6.15516245e-01 -3.73692155e-01\n",
      "   2.18292568e-02  2.07758978e-01]\n",
      " [ 7.56092250e-01  1.41497004e+00  4.40309703e-01 -5.28975308e-01\n",
      "   7.27781594e-01 -7.69836083e-02  2.65192628e-01  3.74454618e-01\n",
      "   3.83654028e-01 -2.98359245e-01]\n",
      " [-8.05571616e-01  4.18231636e-02  2.90237755e-01  7.86091462e-02\n",
      "  -1.70358300e-01 -2.66031504e-01 -3.98338020e-01 -2.61248909e-02\n",
      "  -9.55434084e-01  2.73637891e-01]\n",
      " [-2.03298479e-01  1.75729115e-02 -2.42504254e-01  7.73410201e-01\n",
      "   1.13743699e+00 -8.77966523e-01 -2.29445472e-02  8.18851352e-01\n",
      "  -2.57356707e-02 -6.10880256e-01]\n",
      " [ 6.35107040e-01  3.52465272e-01 -1.75668940e-01 -6.99841559e-01\n",
      "  -2.61184394e-01 -8.71045701e-03  3.24261755e-01 -3.60376447e-01\n",
      "   1.31614268e+00 -6.74559176e-01]\n",
      " [-4.23066854e-01  5.41674644e-02  4.24486041e-01 -1.09562866e-01\n",
      "   1.47551402e-01  1.02872908e-01  1.65007964e-01 -2.05084801e-01\n",
      "  -2.07608029e-01 -1.30811080e-01]\n",
      " [ 1.62257953e-03  2.74453938e-01  8.24525476e-01 -6.64776862e-01\n",
      "   1.56820029e-01  6.07680202e-01 -2.86219530e-02 -1.89410716e-01\n",
      "   6.30771741e-02 -4.83834483e-02]\n",
      " [-9.23361719e-01 -4.37621772e-01  2.13198230e-01  9.55424011e-02\n",
      "  -4.34605896e-01 -3.36863063e-02 -1.85415551e-01  2.15018034e-01\n",
      "   4.23501670e-01 -1.49123251e-01]\n",
      " [ 1.60803407e-01  6.71615660e-01 -1.71006367e-01  4.32196558e-01\n",
      "   9.11247849e-01  1.34682544e-02  4.86294068e-02  4.99737382e-01\n",
      "   6.18646085e-01  1.37868941e-01]\n",
      " [-4.57778752e-01 -9.61101353e-02  1.18076301e+00  4.29673105e-01\n",
      "  -7.30640829e-01 -5.26811481e-01 -2.76298404e-01  1.47503808e-01\n",
      "  -1.80512816e-01 -1.04018018e-01]\n",
      " [ 6.16749704e-01 -5.41009724e-01 -8.73399734e-01 -5.40236235e-01\n",
      "  -2.62838751e-01  4.17431861e-01  2.80850768e-01 -1.28120208e+00\n",
      "  -6.41396046e-02 -3.01971406e-01]\n",
      " [-5.70315123e-01 -3.42667550e-01  9.59355652e-01 -2.52577782e-01\n",
      "  -2.13143393e-01  4.32799518e-01 -6.98083043e-01  2.36423582e-01\n",
      "   2.48593703e-01 -7.65703857e-01]\n",
      " [-2.73810983e-01  6.60891116e-01 -4.34846520e-01 -2.38066353e-02\n",
      "   2.31896937e-01 -3.25802803e-01 -1.86076507e-01 -5.22267163e-01\n",
      "  -1.42088413e-01 -5.55052876e-01]\n",
      " [-1.30619153e-01 -1.15639377e+00  1.37374401e+00 -5.92736602e-02\n",
      "  -4.21481222e-01  1.75909460e-01  1.53388664e-01 -2.63784438e-01\n",
      "  -1.09382667e-01 -1.78310886e-01]\n",
      " [-2.10618705e-01 -2.04434488e-02  4.17681932e-01 -3.62328827e-01\n",
      "   2.77620498e-02  7.51803041e-01  2.48888984e-01 -7.02374578e-01\n",
      "   4.52694982e-01 -5.43105900e-01]\n",
      " [ 8.54377914e-03 -6.40325010e-01  9.58496213e-01  2.47877732e-01\n",
      "   6.35959029e-01 -3.56694967e-01  6.73443004e-02 -1.61919653e-01\n",
      "  -4.90821898e-01 -1.31845668e-01]\n",
      " [-8.74849319e-01  2.94289321e-01 -1.27668262e+00 -7.65141129e-01\n",
      "  -6.59890413e-01 -8.28669071e-01 -2.09173992e-01  2.57274657e-01\n",
      "   7.49174416e-01  2.10680157e-01]\n",
      " [-1.95544109e-01 -5.96271396e-01  5.15818238e-01 -5.92480041e-02\n",
      "  -6.31647408e-01 -1.29120469e+00 -1.17712572e-01 -1.01250482e+00\n",
      "   1.98320284e-01  3.09023380e-01]\n",
      " [ 1.21289017e-02 -1.01803288e-01 -6.57945633e-01  5.45512259e-01\n",
      "   2.31195301e-01  2.15975434e-01  2.83488721e-01 -7.06345022e-01\n",
      "   1.03127253e+00 -4.72522795e-01]\n",
      " [-9.01605844e-01 -9.00073051e-01 -3.25709403e-01  1.06196594e+00\n",
      "   8.49843144e-01  6.87932670e-01  1.18468575e-01 -1.40070319e-01\n",
      "   8.87280703e-01 -5.49519122e-01]\n",
      " [ 5.34725010e-01  1.94996312e-01 -2.10387155e-01  7.47731328e-01\n",
      "  -1.88560337e-02 -3.28707129e-01 -6.27564609e-01  1.15781292e-01\n",
      "   5.18955886e-01  7.93187737e-01]\n",
      " [ 6.08518124e-01  7.57394850e-01  5.29032275e-02  1.00519963e-01\n",
      "   1.03769088e+00  4.13046241e-01 -7.37064004e-01  1.69239715e-01\n",
      "  -5.25928140e-01  7.83107042e-01]\n",
      " [ 1.42203462e+00  5.12111068e-01  6.84850812e-01 -4.74574745e-01\n",
      "   2.00504139e-01  1.56046271e-01  7.01838732e-01 -1.25587896e-01\n",
      "   7.63753951e-01  2.35032514e-01]\n",
      " [-1.71991244e-01  6.41710520e-01  6.14383698e-01  5.56162238e-01\n",
      "   8.15961778e-01  5.07055044e-01 -5.31304061e-01 -3.39170545e-01\n",
      "   4.20213342e-01 -7.73664773e-01]\n",
      " [ 5.77085018e-01  2.51686782e-01 -3.30798954e-01  1.39501190e+00\n",
      "   5.73589467e-02  4.10604179e-01 -1.70556903e-02 -6.49198294e-01\n",
      "   5.93377411e-01  4.37106937e-01]\n",
      " [ 5.61360240e-01 -4.40489829e-01  3.92625034e-01 -1.57892138e-01\n",
      "  -1.58859983e-01 -9.10637975e-01  4.77585584e-01  7.10551083e-01\n",
      "   3.57449293e-01  5.99991754e-02]\n",
      " [ 1.04693353e+00 -2.06562746e-02 -3.92619193e-01  4.29511368e-02\n",
      "  -4.21434313e-01 -5.74409902e-01 -8.12951803e-01 -1.85155779e-01\n",
      "   2.98913121e-01 -1.80895049e-02]\n",
      " [-2.16858879e-01  4.83917356e-01 -2.65324622e-01 -4.68690515e-01\n",
      "   4.00994480e-01 -9.19797897e-01  4.61978287e-01  8.01518500e-01\n",
      "  -2.13681534e-02 -5.16968846e-01]\n",
      " [-3.15357089e-01  1.02975261e+00 -1.30032957e-01  2.95838356e-01\n",
      "  -8.63512695e-01  5.85305452e-01 -1.83951452e-01 -6.26038492e-01\n",
      "   3.67659509e-01 -4.14675802e-01]\n",
      " [-5.36699772e-01  4.72155929e-01 -3.17433715e-01 -4.03907448e-01\n",
      "  -2.20506683e-01 -3.04877991e-03  7.36495018e-01  1.11329956e-02\n",
      "   2.83995092e-01 -3.07262456e-03]\n",
      " [ 2.84792095e-01 -4.39019084e-01  5.72442114e-01  5.15148640e-01\n",
      "   3.87972295e-01 -5.25556922e-01  7.96575844e-01  1.29740089e-01\n",
      "   2.15324983e-01  1.48875332e+00]\n",
      " [ 5.77128768e-01 -4.04225558e-01  2.68244147e-01 -5.41207120e-02\n",
      "  -8.63196790e-01  4.91594225e-02  3.31961215e-01  4.14583534e-01\n",
      "   1.26805648e-01 -8.03543866e-01]\n",
      " [ 4.91567761e-01  3.27581942e-01 -1.13335676e-01 -4.44217891e-01\n",
      "   1.74909428e-01 -3.42304558e-01 -1.41133890e-01  4.33672182e-02\n",
      "  -5.18144667e-01 -6.88817441e-01]\n",
      " [ 2.15260774e-01 -7.13233650e-02  4.55192268e-01  1.33064377e+00\n",
      "  -8.59020174e-01 -7.36954436e-02  1.23971283e-01 -1.73815459e-01\n",
      "   1.28138706e-01 -5.17334461e-01]\n",
      " [-9.64119613e-01 -8.30194533e-01 -2.58907024e-02 -3.27495515e-01\n",
      "   2.40298152e-01  5.13646185e-01  2.17427596e-01  4.60653454e-01\n",
      "   1.81737733e+00  2.36709550e-01]\n",
      " [ 2.13940442e-01  8.46519589e-01 -2.51826197e-01  4.80582982e-01\n",
      "  -6.26426399e-01 -2.14791536e-01 -6.46318436e-01  6.56872869e-01\n",
      "  -3.53700906e-01  4.63206798e-01]\n",
      " [ 3.68748218e-01 -4.82747376e-01  3.68933052e-01  1.28926069e-01\n",
      "   1.29698351e-01  3.62892449e-01 -6.68679416e-01 -8.21636379e-01\n",
      "   1.98380113e-01 -2.25566506e-01]\n",
      " [ 2.04901859e-01  2.92769551e-01 -4.32865679e-01  5.54555297e-01\n",
      "   3.41025367e-02 -8.55921030e-01 -3.25892091e-01 -5.51421121e-02\n",
      "   1.66161194e-01 -1.35097638e-01]\n",
      " [ 3.64831328e-01  8.41059804e-01 -3.86724979e-01 -6.38074040e-01\n",
      "  -1.65338612e+00  4.61966753e-01 -7.92782068e-01 -2.23048851e-01\n",
      "   9.78556931e-01  4.75408323e-02]\n",
      " [-1.79299504e-01 -1.49331599e-01 -9.66474533e-01  1.27330050e-01\n",
      "  -2.43673667e-01  8.49859357e-01 -4.69742388e-01  9.39391792e-01\n",
      "   4.91078556e-01  1.30477950e-01]\n",
      " [-1.81044698e-01 -7.19432175e-01 -1.26964402e+00 -1.22295871e-01\n",
      "  -8.80622625e-01  8.54390413e-02  5.57272792e-01 -2.97118902e-01\n",
      "  -5.37232161e-01  2.83553421e-01]\n",
      " [ 9.98358950e-02 -3.56937587e-01  2.71550566e-01 -3.73795591e-02\n",
      "  -4.43160802e-01 -1.09973681e+00 -4.03908283e-01 -5.19003332e-01\n",
      "   7.62368560e-01  6.39927313e-02]\n",
      " [ 4.45913315e-01 -7.11327672e-01 -1.05067086e+00 -4.15295660e-01\n",
      "   7.87519738e-02  5.51144302e-01 -8.54692832e-02  1.05039954e+00\n",
      "  -9.35472727e-01 -3.30546796e-01]\n",
      " [ 4.56187218e-01 -1.53621510e-01 -1.13403708e-01  8.04673955e-02\n",
      "  -6.46312118e-01 -2.88660288e-01  2.30976999e-01  3.95243466e-01\n",
      "  -4.53089744e-01 -6.40690625e-01]\n",
      " [-5.94321132e-01 -4.14378159e-02  4.58679438e-01 -2.86935419e-01\n",
      "   1.28420427e-01  1.30794120e+00 -7.53466156e-04  3.31711799e-01\n",
      "  -2.94006616e-01  1.96553189e-02]\n",
      " [-5.74742794e-01 -2.61439681e-01  5.91234684e-01  2.52867132e-01\n",
      "  -2.52762139e-01 -4.07721549e-01 -2.47759685e-01  7.99494445e-01\n",
      "  -7.67632186e-01 -5.40443301e-01]\n",
      " [ 6.14871621e-01 -3.90362918e-01  1.84516534e-02 -4.08785306e-02\n",
      "   7.35430479e-01 -8.08110058e-01 -1.12600170e-01 -2.63114750e-01\n",
      "   8.10686685e-03  1.49745911e-01]\n",
      " [-2.43230715e-01 -3.48754562e-02 -4.66352224e-01 -5.05633771e-01\n",
      "  -1.36753649e-01 -7.30619907e-01 -2.92184800e-02 -1.16662711e-01\n",
      "  -1.96931183e-01  1.65745139e-01]\n",
      " [ 5.63288987e-01  4.49480087e-01 -2.78169930e-01  2.38695264e-01\n",
      "  -5.55653393e-01 -2.75876164e-01  4.88264978e-01  1.12162328e+00\n",
      "  -1.03402503e-01  3.04986656e-01]\n",
      " [ 1.18914580e+00 -1.11506057e+00  4.11430478e-01 -1.15494668e-01\n",
      "  -4.23629701e-01  3.34681839e-01 -1.49825305e-01 -1.22205414e-01\n",
      "  -2.76276052e-01  1.14043438e+00]\n",
      " [ 6.17224351e-02 -1.33600220e-01  5.73041677e-01 -4.20644879e-01\n",
      "  -3.63062710e-01  4.59396034e-01 -2.18659133e-01  1.23085225e+00\n",
      "  -4.16583806e-01 -4.25998241e-01]\n",
      " [-7.29808025e-03 -7.55842179e-02 -3.35058212e-01  1.33727252e-01\n",
      "  -8.07022005e-02  1.49762392e-01  5.57795703e-01 -3.37723881e-01\n",
      "  -6.07368827e-01  3.11406702e-01]\n",
      " [ 5.32902718e-01 -8.65164306e-03 -1.57372415e-01 -1.53640723e-02\n",
      "  -1.42011672e-01  3.34173590e-01  4.06270236e-01  5.27561247e-01\n",
      "  -4.94037032e-01 -1.22297518e-01]\n",
      " [ 8.62294316e-01 -2.47640863e-01  1.70408174e-01 -3.53190422e-01\n",
      "  -6.48006678e-01 -4.01323944e-01  2.86077186e-02 -5.94932120e-03\n",
      "   4.62806374e-01 -8.26096475e-01]\n",
      " [ 6.29324675e-01 -8.43611360e-01 -3.46858978e-01 -5.96780658e-01\n",
      "   1.17275894e+00  1.01314209e-01  2.90248096e-02  4.29866165e-01\n",
      "   6.82533741e-01 -3.45210969e-01]\n",
      " [ 3.57265621e-01  2.04840928e-01 -1.06853373e-01 -2.06199735e-01\n",
      "  -2.52168812e-02 -3.32167327e-01  3.92506301e-01 -4.13992941e-01\n",
      "  -6.77734613e-02 -1.04096174e+00]\n",
      " [-8.10485005e-01  1.31481147e+00  7.49214351e-01 -5.69186211e-02\n",
      "   1.11144197e+00 -6.97757602e-01  1.05565715e+00  7.37762004e-02\n",
      "  -4.31669742e-01  1.18558392e-01]\n",
      " [-2.47681573e-01  8.53562653e-02  7.95246184e-01 -9.35757399e-01\n",
      "   4.43015873e-01 -6.60197958e-02 -4.81123269e-01 -2.40884006e-01\n",
      "  -3.32881182e-01 -3.05340797e-01]\n",
      " [-2.93352127e-01  7.83656538e-01 -1.05684839e-01  2.78722525e-01\n",
      "  -2.59447008e-01  6.05542958e-02 -8.28648448e-01  1.43983454e-01\n",
      "  -5.46816587e-01 -1.44283444e-01]\n",
      " [ 2.15460300e-01  5.66638708e-01  5.71224034e-01  6.10781275e-02\n",
      "  -8.01203474e-02  1.28122672e-01  3.32013220e-01  8.92787501e-02\n",
      "  -5.52756846e-01  8.98777902e-01]\n",
      " [-3.90882552e-01 -2.55867749e-01  6.49341881e-01 -8.78780305e-01\n",
      "  -2.93446928e-01 -1.13643265e+00 -5.84040284e-01 -9.56421912e-01\n",
      "   2.05127388e-01  1.15097010e+00]\n",
      " [-6.00446105e-01  1.98836345e-02 -3.58150274e-01  1.24724455e-01\n",
      "   4.20149326e-01 -7.21011087e-02 -4.21910286e-01 -2.15895072e-01\n",
      "   3.23120505e-01  6.91294551e-01]\n",
      " [-1.78865075e-01  2.26041809e-01 -8.01966369e-01  7.34823406e-01\n",
      "   2.51124471e-01 -4.22440529e-01 -2.32503697e-01  4.97502387e-01\n",
      "  -1.07011862e-01  1.42923784e+00]\n",
      " [ 4.51788485e-01 -3.42997581e-01  4.43697982e-02  1.82180300e-01\n",
      "  -5.26873469e-01 -3.42721403e-01  1.05890788e-01  4.44317400e-01\n",
      "   4.54780519e-01 -6.92542970e-01]\n",
      " [-2.31588840e-01  7.07424879e-02  9.70020816e-02  2.27063328e-01\n",
      "  -6.82133019e-01  7.42444873e-01  7.54442453e-01 -4.77362484e-01\n",
      "  -2.46198773e-01 -7.52300620e-01]\n",
      " [ 8.18466917e-02 -1.88975129e-02 -1.66564077e-01  1.40121296e-01\n",
      "   2.62126952e-01  5.77022254e-01 -1.05909622e+00  2.32029051e-01\n",
      "   1.47185847e-02  5.97116530e-01]\n",
      " [-1.39892459e-01  3.73720467e-01 -1.31472695e+00  3.67564440e-01\n",
      "  -1.70168892e-01 -9.15726125e-01 -1.87860340e-01 -1.33281493e+00\n",
      "  -6.38347268e-01  1.93468347e-01]\n",
      " [ 5.92577636e-01 -2.50661939e-01  6.72015399e-02  2.47015253e-01\n",
      "   5.50856292e-01  1.08759299e-01 -7.19901025e-02 -2.74261534e-01\n",
      "  -1.31686822e-01 -6.36621296e-01]]\n",
      "\n",
      "Private components for view 1 (U1):\n",
      " [[ 9.23679695e-02  3.87413144e-01  2.08226934e-01  9.16987890e-04\n",
      "  -5.87894954e-02 -2.70406783e-01  3.51107538e-01 -2.47690871e-01\n",
      "   2.40054384e-01  8.81520063e-02]\n",
      " [ 2.06390209e-02 -1.33235469e-01  2.24290371e-01  2.02157408e-01\n",
      "  -4.91103455e-02 -3.09009999e-01 -3.17646146e-01  6.37574568e-02\n",
      "  -1.70550898e-01  2.81168763e-02]\n",
      " [-2.52066940e-01  1.48475736e-01 -4.30285722e-01  1.95669308e-01\n",
      "   1.58693179e-01  5.78304939e-02  5.92478663e-02 -4.30324785e-02\n",
      "  -4.82535660e-02  1.93116531e-01]\n",
      " [ 2.49997675e-01 -3.02520040e-02 -3.12341452e-02  9.73056778e-02\n",
      "  -3.89206648e-01  3.65711451e-01 -1.12533048e-02 -2.60524154e-01\n",
      "  -9.36545581e-02 -6.48453087e-02]\n",
      " [ 3.88676018e-01  3.06352347e-01 -2.06897154e-01 -2.73186080e-02\n",
      "   6.58770382e-01  1.03594355e-01 -4.76417616e-02 -5.41998483e-02\n",
      "  -9.94798094e-02 -2.31910646e-01]\n",
      " [-2.25084089e-02 -1.57200173e-01 -2.17208907e-01  8.31189230e-02\n",
      "  -5.32969721e-02 -5.91414571e-01  3.87908481e-02  2.49933243e-01\n",
      "  -2.17792973e-01 -1.88786700e-01]\n",
      " [-1.77152380e-02 -2.52808630e-01 -2.43699793e-02  2.64892727e-01\n",
      "   1.35406971e-01 -1.65858105e-01  4.72134799e-02 -1.74373627e-01\n",
      "   5.61165214e-02  5.84945083e-05]\n",
      " [ 3.44930142e-02 -1.33905590e-01 -3.62833478e-02 -2.44856045e-01\n",
      "  -2.27111518e-01 -7.78779062e-03 -8.35084021e-02 -1.22353904e-01\n",
      "  -1.27701193e-01  5.59171475e-02]\n",
      " [-2.22038358e-01 -6.04297891e-02 -1.49157450e-01 -8.58565494e-02\n",
      "  -2.15550974e-01 -1.12630785e-01  3.78336579e-01 -1.22408986e-01\n",
      "  -8.52875318e-03 -9.87543389e-02]\n",
      " [-2.92548269e-01 -5.41319232e-03 -3.63537157e-03 -2.96415031e-01\n",
      "  -5.73103465e-02 -2.97497302e-01 -6.81356266e-02 -4.96853888e-02\n",
      "   1.14317387e-01  2.72587568e-01]\n",
      " [-3.40097956e-02  2.86345661e-01  4.42033447e-02  4.79267947e-02\n",
      "  -2.45411873e-01 -2.43275702e-01  2.00529963e-01 -1.67961866e-01\n",
      "  -3.55806686e-02  5.49394712e-02]\n",
      " [-1.26306891e-01 -2.68733621e-01 -2.03866046e-02  2.84939408e-02\n",
      "  -1.43905327e-01  5.13516068e-01  2.59578407e-01 -2.46481910e-01\n",
      "   1.83638066e-01 -1.31352931e-01]\n",
      " [ 2.23321512e-01 -1.17378712e-01  3.52631956e-01 -1.35867327e-01\n",
      "   1.00746140e-01  1.05117120e-01  2.22796306e-01  3.88644755e-01\n",
      "   1.64221272e-01 -2.01504901e-01]\n",
      " [ 6.27478063e-02 -4.99040000e-02  2.72375643e-01  9.44337994e-02\n",
      "  -2.38021389e-01  2.01135054e-02 -5.98345622e-02 -4.64703292e-01\n",
      "   1.70494840e-02  2.39535794e-01]\n",
      " [ 1.39096886e-01  7.03394413e-02 -1.87302291e-01 -4.24185246e-02\n",
      "   1.35995880e-01  1.95844665e-01  1.34499609e-01  2.54966021e-01\n",
      "   5.23974374e-02  3.22859108e-01]\n",
      " [-5.36175668e-01  2.13492960e-01 -1.39026985e-01 -2.16418907e-01\n",
      "   1.00362368e-01  4.26544361e-02  9.35319066e-02 -3.07523549e-01\n",
      "  -1.47990305e-02  9.30870697e-03]\n",
      " [-1.57724082e-01 -5.76628819e-02  1.25180259e-01 -7.28321224e-02\n",
      "  -8.10985118e-02  3.96609575e-01  1.12557441e-01 -1.78373046e-02\n",
      "  -1.57590821e-01 -1.30412340e-01]\n",
      " [ 4.31548990e-02  4.58809398e-02 -8.34754631e-02  8.67136866e-02\n",
      "   1.72070079e-02 -1.61612466e-01 -9.81122330e-02 -2.93569386e-01\n",
      "   2.46673133e-02  3.29827994e-01]\n",
      " [ 2.40065649e-01  2.79859990e-01 -1.56781361e-01  8.15791562e-02\n",
      "  -5.77789843e-01  1.03446215e-01 -2.48035252e-01 -2.68756688e-01\n",
      "  -1.41090006e-01 -1.95992246e-01]\n",
      " [ 1.20410003e-01 -1.02772616e-01  6.29660338e-02  4.01749238e-02\n",
      "   3.15808624e-01  1.83477759e-01  3.13665301e-01  8.76394361e-02\n",
      "  -3.58761922e-02 -2.31241614e-01]]\n",
      "\n",
      "Private components for view 2 (U2):\n",
      " [[-1.20168693e-01 -6.34536967e-02  1.74180046e-01  1.30280912e-01\n",
      "  -7.45705366e-02  3.84548157e-02 -1.59147829e-02  1.94102317e-01\n",
      "   2.42978320e-01 -4.08670127e-01]\n",
      " [-3.65473092e-01  2.74004668e-01  1.68006718e-01  2.17082322e-01\n",
      "   2.14944929e-01  1.12880163e-01  1.26189724e-01  1.78483158e-01\n",
      "   1.56801805e-01 -1.71847250e-02]\n",
      " [-1.41978785e-01  5.98658919e-01  2.01690830e-02 -1.02503225e-01\n",
      "   1.14200480e-01 -3.46400470e-01 -6.35857508e-02  1.53508484e-01\n",
      "  -7.89816976e-02  3.66261870e-01]\n",
      " [ 3.56498748e-01  3.39938223e-01 -1.34319663e-01  3.37709129e-01\n",
      "  -6.11833185e-02 -2.83029843e-02  1.94031801e-02  1.23331301e-01\n",
      "   1.17681712e-01  1.09144643e-01]\n",
      " [ 2.64290303e-01  3.63764912e-02 -1.62973881e-01 -4.07823175e-01\n",
      "   1.50346339e-01 -8.56402069e-02  1.49345815e-01  2.00236961e-03\n",
      "  -2.09041312e-01 -1.83124065e-01]\n",
      " [ 1.26722679e-01  3.05893332e-01  5.17945409e-01  1.45015821e-01\n",
      "  -4.62005921e-02  7.79480021e-03  4.27178070e-02  1.02532886e-01\n",
      "  -1.22403339e-01  7.42555112e-02]\n",
      " [-6.75370842e-02 -5.29173249e-03  2.63774633e-01 -6.48235083e-02\n",
      "   4.98742431e-01 -1.73688605e-01  1.59522966e-01  3.74533713e-01\n",
      "   1.30031735e-01  1.72571138e-01]\n",
      " [ 2.05670133e-01 -2.61558145e-01  5.95505647e-02 -2.94298232e-01\n",
      "  -3.17769796e-02  2.01170892e-01  5.40293038e-01 -2.32442185e-01\n",
      "   3.58035296e-01  1.74737841e-01]\n",
      " [-1.22357495e-01  2.14116544e-01 -4.65488061e-02 -3.26210596e-02\n",
      "   8.62058774e-02 -2.84120301e-03  1.03864357e-01 -4.98278975e-01\n",
      "   3.45833115e-02 -3.58074278e-01]\n",
      " [-1.67890877e-01  3.66274506e-01 -1.32291585e-01 -1.61681414e-01\n",
      "  -1.71343863e-01  3.08330536e-01 -1.18267477e-01  4.72005099e-01\n",
      "  -3.35199870e-02 -2.92765647e-02]\n",
      " [-7.42341112e-03 -1.74081311e-01  2.49449797e-02 -5.61634377e-02\n",
      "  -2.72165686e-01  1.84798211e-01 -1.12630442e-01  3.46175462e-01\n",
      "  -2.05993310e-01 -2.26631954e-01]\n",
      " [-2.69647181e-01  1.85051322e-01  2.69135088e-01  2.35690787e-01\n",
      "  -2.73676634e-01  2.89065003e-01  3.89978945e-01 -3.25275469e-04\n",
      "  -1.26863152e-01  5.48199490e-02]\n",
      " [-1.73143834e-01  4.75925416e-01 -3.59453708e-02 -8.54840428e-02\n",
      "   1.41848579e-01 -5.39224669e-02  9.87990424e-02 -4.04345915e-02\n",
      "  -1.85017902e-02 -1.50551200e-01]\n",
      " [-2.09129006e-01 -4.11340445e-01 -1.53463846e-03 -1.98160529e-01\n",
      "  -8.40224326e-03 -6.38156459e-02  8.64561647e-02 -2.26763859e-01\n",
      "   2.71701992e-01 -3.80649269e-01]\n",
      " [-4.38330621e-02  5.23838401e-02 -4.91279662e-01  1.78211406e-01\n",
      "  -1.35987461e-01 -1.67013466e-01  3.07317913e-01 -3.18214566e-01\n",
      "   1.94811091e-01 -1.08198278e-01]\n",
      " [ 7.47816041e-02  2.80272383e-02 -3.13572288e-01 -3.55912000e-02\n",
      "  -2.61290282e-01 -2.04473689e-01 -2.17590258e-01 -2.28828005e-02\n",
      "   5.13512753e-02  5.87477684e-02]\n",
      " [ 9.94294882e-02  2.04039752e-01  4.41608131e-02 -1.61448509e-01\n",
      "  -2.40233928e-01  1.17866278e-01  4.44530845e-01  1.28716603e-01\n",
      "  -2.05886096e-01 -3.22155729e-02]\n",
      " [-4.95088473e-02 -1.74812272e-01 -2.94373602e-01 -2.32875422e-01\n",
      "  -1.37575343e-01  1.19182415e-01 -7.11918175e-02 -1.86972290e-01\n",
      "   3.23245704e-01  3.06501657e-01]\n",
      " [ 1.32119939e-01  1.38594806e-01 -1.80023283e-01  3.74474108e-01\n",
      "   1.61396518e-01 -1.35007367e-01  3.04891765e-01 -1.17792219e-01\n",
      "  -2.30773568e-01 -2.33936608e-02]\n",
      " [-9.68039855e-02  1.35732785e-01  3.65544021e-01  1.82047412e-01\n",
      "   8.16364214e-02  4.88046706e-02 -1.95023745e-01 -1.04318164e-01\n",
      "   1.62942111e-01 -4.02494639e-01]\n",
      " [ 1.29432783e-01 -2.50994861e-02  2.27435991e-01 -5.99123947e-02\n",
      "   1.06853493e-01  7.15664448e-03 -2.30071589e-01 -8.83966591e-03\n",
      "   3.75490248e-01 -2.28958026e-01]\n",
      " [ 3.12129378e-01  2.14570314e-01 -3.08799118e-01 -1.45390168e-01\n",
      "  -2.64283270e-01 -2.43229613e-01  5.54928221e-02  3.64173263e-01\n",
      "   3.04109424e-01  1.00803971e-02]\n",
      " [-1.32705256e-01  2.45647073e-01 -3.47297311e-01 -2.27167174e-01\n",
      "  -7.35317990e-02  4.36177909e-01 -2.07402259e-01  2.51045108e-01\n",
      "   1.39743820e-01  2.66449191e-02]\n",
      " [ 1.66250333e-01 -1.10613897e-01  2.20464244e-01 -2.79937148e-01\n",
      "   2.85124570e-01  1.02297693e-01  2.80522220e-02 -2.77093321e-01\n",
      "  -6.32144272e-01  2.10920557e-01]\n",
      " [-9.59196985e-02  2.77092934e-01  3.10188457e-02 -8.58041868e-02\n",
      "   2.09144115e-01  6.51527718e-02 -1.30971417e-01 -7.06925094e-01\n",
      "   1.96986690e-01 -7.60912374e-02]\n",
      " [-3.21672380e-01 -3.84858221e-01 -3.03677469e-01  2.02691197e-01\n",
      "  -4.57494147e-02 -1.68013886e-01 -1.71553671e-01  1.74198717e-01\n",
      "  -2.36568883e-01  8.45793821e-03]\n",
      " [ 5.60520552e-02  1.48069561e-01 -3.43140125e-01  2.85738051e-01\n",
      "   2.49735668e-01  3.97776544e-01 -1.63262874e-01 -1.55316174e-01\n",
      "   4.82341237e-02 -2.87574589e-01]\n",
      " [-1.41159864e-02  1.67754471e-01  1.70400038e-01 -6.19178936e-02\n",
      "   2.52819419e-01  1.23325512e-02 -5.54356948e-02 -7.48900697e-02\n",
      "  -1.25999779e-01 -3.23472500e-01]\n",
      " [ 1.04459725e-01 -8.37176442e-02 -1.61728755e-01 -8.40864778e-02\n",
      "  -2.82764658e-02 -5.16043663e-01  1.12901695e-01 -5.09919692e-03\n",
      "   2.31099613e-02  1.69251516e-01]\n",
      " [ 4.85036001e-02  1.29147246e-01  8.52573663e-02 -4.59253192e-01\n",
      "  -8.41713548e-02 -1.20534830e-01  1.92900039e-02 -2.77593955e-02\n",
      "  -2.90161937e-01 -4.39076543e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "class MultiViewFactorization(nn.Module):\n",
    "    def __init__(self, num_samples, num_features1, num_features2, num_factors):\n",
    "        super(MultiViewFactorization, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.num_features1 = num_features1\n",
    "        self.num_features2 = num_features2\n",
    "        self.num_factors = num_factors\n",
    "        \n",
    "        # Initialize shared latent factors\n",
    "        self.S = nn.Parameter(torch.randn(num_samples, num_factors))\n",
    "        \n",
    "        # Initialize private latent factors for each view\n",
    "        self.U1 = nn.Parameter(torch.randn(num_features1, num_factors))\n",
    "        self.U2 = nn.Parameter(torch.randn(num_features2, num_factors))\n",
    "\n",
    "    def model(self, X1, X2):\n",
    "        # Priors\n",
    "        S_prior = dist.Normal(torch.zeros(self.num_samples, self.num_factors), torch.ones(self.num_samples, self.num_factors)).to_event(2)\n",
    "        U1_prior = dist.Normal(torch.zeros(self.num_features1, self.num_factors), torch.ones(self.num_features1, self.num_factors)).to_event(2)\n",
    "        U2_prior = dist.Normal(torch.zeros(self.num_features2, self.num_factors), torch.ones(self.num_features2, self.num_factors)).to_event(2)\n",
    "        \n",
    "        # Sample from priors\n",
    "        S = pyro.sample('S', S_prior)\n",
    "        U1 = pyro.sample('U1', U1_prior)\n",
    "        U2 = pyro.sample('U2', U2_prior)\n",
    "        \n",
    "        # Likelihood\n",
    "        X1_hat = torch.matmul(S, U1.T)\n",
    "        X2_hat = torch.matmul(S, U2.T)\n",
    "        \n",
    "        with pyro.plate('data1', X1.shape[0]):\n",
    "            pyro.sample('obs1', dist.Normal(X1_hat, 1.0).to_event(1), obs=X1)\n",
    "        \n",
    "        with pyro.plate('data2', X2.shape[0]):\n",
    "            pyro.sample('obs2', dist.Normal(X2_hat, 1.0).to_event(1), obs=X2)\n",
    "\n",
    "    def guide(self, X1, X2):\n",
    "        # Variational distributions\n",
    "        S_loc = pyro.param('S_loc', torch.randn(self.num_samples, self.num_factors))\n",
    "        S_scale = pyro.param('S_scale', torch.ones(self.num_samples, self.num_factors), constraint=dist.constraints.positive)\n",
    "        U1_loc = pyro.param('U1_loc', torch.randn(self.num_features1, self.num_factors))\n",
    "        U1_scale = pyro.param('U1_scale', torch.ones(self.num_features1, self.num_factors), constraint=dist.constraints.positive)\n",
    "        U2_loc = pyro.param('U2_loc', torch.randn(self.num_features2, self.num_factors))\n",
    "        U2_scale = pyro.param('U2_scale', torch.ones(self.num_features2, self.num_factors), constraint=dist.constraints.positive)\n",
    "        \n",
    "        S_dist = dist.Normal(S_loc, S_scale).to_event(2)\n",
    "        U1_dist = dist.Normal(U1_loc, U1_scale).to_event(2)\n",
    "        U2_dist = dist.Normal(U2_loc, U2_scale).to_event(2)\n",
    "        \n",
    "        pyro.sample('S', S_dist)\n",
    "        pyro.sample('U1', U1_dist)\n",
    "        pyro.sample('U2', U2_dist)\n",
    "\n",
    "# Example usage:\n",
    "num_samples = 100\n",
    "num_features1 = 20\n",
    "num_features2 = 30\n",
    "num_factors = 10\n",
    "num_iterations = 5000\n",
    "\n",
    "# Generate synthetic data\n",
    "X1 = torch.randn(num_samples, num_features1)\n",
    "X2 = torch.randn(num_samples, num_features2)\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiViewFactorization(num_samples, num_features1, num_features2, num_factors)\n",
    "\n",
    "# Setup the optimizer and the inference algorithm\n",
    "optimizer = Adam({\"lr\": 0.02})\n",
    "svi = SVI(model.model, model.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Train the model\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(X1, X2)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i} : loss = {loss}\")\n",
    "\n",
    "# Get the learned latent factors\n",
    "S_posterior = pyro.param(\"S_loc\").detach().numpy()\n",
    "U1_posterior = pyro.param(\"U1_loc\").detach().numpy()\n",
    "U2_posterior = pyro.param(\"U2_loc\").detach().numpy()\n",
    "\n",
    "print(\"Shared components (S):\\n\", S_posterior)\n",
    "print(\"\\nPrivate components for view 1 (U1):\\n\", U1_posterior)\n",
    "print(\"\\nPrivate components for view 2 (U2):\\n\", U2_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 243590.5446\n",
      "Step 100 : loss = 150250.5604\n",
      "Step 200 : loss = 142902.5009\n",
      "Step 300 : loss = 141011.0393\n",
      "Step 400 : loss = 140425.8809\n",
      "Step 500 : loss = 140092.1438\n",
      "Step 600 : loss = 139954.9001\n",
      "Step 700 : loss = 139929.7815\n",
      "Step 800 : loss = 139918.1588\n",
      "Step 900 : loss = 139859.0770\n",
      "Step 1000 : loss = 139876.7594\n",
      "Step 1100 : loss = 139833.7688\n",
      "Step 1200 : loss = 139791.3052\n",
      "Step 1300 : loss = 139820.4505\n",
      "Step 1400 : loss = 139841.3021\n",
      "Step 1500 : loss = 139885.2786\n",
      "Step 1600 : loss = 139850.6435\n",
      "Step 1700 : loss = 139884.9763\n",
      "Step 1800 : loss = 139837.1411\n",
      "Step 1900 : loss = 139819.0336\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared components (S):\n",
      " [[-8.63709211e-01  2.09232390e-01  8.24061096e-01 -2.72854328e-01\n",
      "   1.47850260e-01  2.77108520e-01  1.97326913e-01  1.29438844e-02\n",
      "  -1.61517859e-01  3.34947288e-01]\n",
      " [-1.32977441e-01  6.48378730e-01  2.62418464e-02  8.96589831e-02\n",
      "   3.44604552e-01  4.55751777e-01  5.83646834e-01  1.22494409e-02\n",
      "  -5.76646984e-01  5.41932344e-01]\n",
      " [-3.79255891e-01 -1.97905675e-01  2.75328249e-01  2.27467835e-01\n",
      "  -2.19322503e-01  2.75572807e-01  4.43844944e-01  9.24141824e-01\n",
      "   1.04378068e+00  4.94581342e-01]\n",
      " [-3.76625299e-01  7.05389321e-01  4.71491396e-01  5.22026479e-01\n",
      "  -2.90651888e-01 -5.63940883e-01  4.52707380e-01  2.06001431e-01\n",
      "   3.10370028e-01 -1.12512540e-02]\n",
      " [-1.08770585e+00  1.43921494e-01  6.08203351e-01  8.48506629e-01\n",
      "  -1.27528101e-01  6.44623786e-02 -2.56117940e-01 -1.21938539e+00\n",
      "   7.23532200e-01  4.47709322e-01]\n",
      " [-1.57225585e+00  1.00532424e+00 -6.80912063e-02 -4.85539466e-01\n",
      "  -1.90644279e-01  7.15210557e-01  1.89457536e-01 -1.43245652e-01\n",
      "  -2.63583243e-01  3.27298373e-01]\n",
      " [ 2.01998532e-01  4.20330822e-01 -4.79353994e-01 -3.83800298e-01\n",
      "  -3.93068880e-01 -9.58864152e-01 -2.75302470e-01  3.45109910e-01\n",
      "   1.80600643e-01  5.91070466e-02]\n",
      " [ 6.18899882e-01  5.11376262e-02  7.77487516e-01  6.93234861e-01\n",
      "   1.07757640e+00  3.73156667e-01  2.08781898e-01  3.85374546e-01\n",
      "   8.18028569e-01 -9.19747949e-01]\n",
      " [ 1.98771715e-01 -2.78900504e-01 -7.63772070e-01 -6.40086174e-01\n",
      "   2.25430448e-03  1.28562137e-01  9.26215529e-01 -1.17653877e-01\n",
      "   8.98330584e-02  5.26204109e-01]\n",
      " [-2.35827416e-01 -2.58553714e-01 -2.06207801e-02 -3.28012943e-01\n",
      "   6.30200028e-01  4.91585910e-01  6.00791536e-02 -9.59302559e-02\n",
      "  -1.34829175e+00 -5.70333779e-01]\n",
      " [-3.78553689e-01  1.60440242e+00  6.72232985e-01 -3.95574450e-01\n",
      "   1.85342655e-01  8.56925100e-02 -3.47222179e-01  2.56361008e-01\n",
      "  -2.16143746e-02  7.04511032e-02]\n",
      " [-5.06315865e-02 -9.74660292e-02  1.03302813e+00  9.09127295e-01\n",
      "   8.75519514e-01 -3.04367781e-01  1.03004664e-01  6.40804231e-01\n",
      "  -1.58525869e-01 -3.98613334e-01]\n",
      " [ 1.14824995e-01 -2.52312630e-01  2.15027973e-01 -6.09499574e-01\n",
      "  -4.28304523e-01 -4.40635502e-01 -3.10738742e-01  1.35018325e+00\n",
      "   1.95971608e-01 -3.10243756e-01]\n",
      " [ 5.28864026e-01 -1.04194395e-02  3.02753188e-02  5.47675788e-01\n",
      "   1.05974779e-01  8.64267886e-01 -1.30988252e+00  5.17650247e-01\n",
      "   1.99155167e-01 -1.78087547e-01]\n",
      " [-2.20845849e-03 -7.20167935e-01 -1.16846764e+00 -2.46173814e-01\n",
      "  -6.54157877e-01  3.79136652e-01  1.19024934e-02  3.74224037e-01\n",
      "  -3.42097208e-02 -7.31838107e-01]\n",
      " [ 9.63695571e-02 -2.43733123e-01  3.83591473e-01 -1.17459916e-01\n",
      "  -1.47282496e-01  1.68277640e-02 -5.46724498e-01 -1.91001245e-03\n",
      "  -9.22881253e-03  1.77762955e-01]\n",
      " [ 5.54255098e-02 -9.55531180e-01 -6.80731460e-02  7.94212878e-01\n",
      "  -5.25470436e-01 -1.07585990e+00  7.97645688e-01  7.29242861e-01\n",
      "   1.04488283e-01  4.74334925e-01]\n",
      " [ 3.18290085e-01  1.57472193e-01 -2.51638174e-01 -7.03763664e-01\n",
      "   4.93336558e-01 -4.26200926e-02 -1.76641852e-01 -1.27968773e-01\n",
      "   1.01530135e+00  1.03270996e+00]\n",
      " [-4.14757907e-01 -5.76185167e-01  3.77079695e-01 -4.26508993e-01\n",
      "  -1.21368408e+00  1.00450933e-01  1.07765540e-01 -2.44080290e-01\n",
      "   1.32719487e-01 -5.95597446e-01]\n",
      " [ 4.91494775e-01  2.59943932e-01 -1.53961092e-01  1.91422060e-01\n",
      "  -7.71534264e-01  5.02721012e-01  6.76072240e-01 -5.50220668e-01\n",
      "  -2.56432891e-01 -4.23216730e-01]\n",
      " [ 4.16367888e-01 -4.33509111e-01 -1.02688223e-01 -6.59863204e-02\n",
      "   1.33310616e-01 -6.69355154e-01 -9.82866168e-01  9.91899818e-02\n",
      "  -6.30138755e-01 -2.21547142e-01]\n",
      " [ 3.96029770e-01  7.34217942e-01  3.19786966e-01 -5.73017932e-02\n",
      "  -2.31384188e-01 -1.04426123e-01  7.55635321e-01  2.85126846e-02\n",
      "  -5.31768799e-01  7.16529369e-01]\n",
      " [-5.36122210e-02  4.18320209e-01 -3.35087299e-01 -1.94244772e-01\n",
      "   3.43962818e-01 -2.52243310e-01  7.65117228e-01 -6.05195224e-01\n",
      "   9.69462544e-02 -5.24351418e-01]\n",
      " [-5.69990873e-01  3.76791686e-01 -9.05160248e-01 -4.25977498e-01\n",
      "  -3.70492041e-01  1.78273335e-01 -4.87164333e-02  6.69303611e-02\n",
      "   8.33986819e-01 -3.15240711e-01]\n",
      " [-8.15490901e-01 -1.18420684e+00 -3.76854122e-01 -3.99297744e-01\n",
      "  -1.72108188e-01  3.30265880e-01  4.76535022e-01  1.59803450e-01\n",
      "   6.33598149e-01 -7.23317116e-02]\n",
      " [-1.60899162e-01  6.24352872e-01 -5.07505462e-02  2.48346761e-01\n",
      "   3.07898130e-02 -3.42054397e-01 -8.24235559e-01  6.34409368e-01\n",
      "   8.28036845e-01 -5.85561693e-01]\n",
      " [-2.21063122e-01  5.42379677e-01 -4.38781619e-01  1.87077358e-01\n",
      "   3.98692906e-01  4.03216809e-01  8.25221241e-01 -8.18061531e-01\n",
      "   7.09954083e-01  3.44361067e-01]\n",
      " [ 3.45118046e-01 -7.17555523e-01 -1.16115332e+00 -1.10576046e+00\n",
      "   5.27849674e-01 -3.42880189e-01 -9.62056872e-03 -4.83477086e-01\n",
      "   5.84369823e-02 -3.52420092e-01]\n",
      " [-1.94542900e-01  8.22856605e-01 -2.65128106e-01  1.06263900e+00\n",
      "   1.11124046e-01 -1.39326148e-03 -2.28122279e-01 -7.08922893e-02\n",
      "  -1.07347178e+00  4.94508773e-01]\n",
      " [ 1.61733136e-01 -1.85227349e-01  4.88614142e-01  3.02891970e-01\n",
      "  -3.12525302e-01  1.11931288e+00  7.32776701e-01  1.31435201e-01\n",
      "  -4.21312958e-01  1.10706091e+00]\n",
      " [ 1.27001774e+00  8.63411665e-01 -5.49986780e-01  4.00426053e-02\n",
      "   4.69363004e-01 -3.06857862e-02 -4.05035824e-01  6.03537410e-02\n",
      "   2.38232404e-01  3.52678597e-01]\n",
      " [-2.13930398e-01 -5.43212056e-01  2.64944583e-01 -5.92584610e-01\n",
      "   1.97107658e-01  8.97166312e-01  7.19114363e-01  2.95317858e-01\n",
      "  -4.24471349e-01 -4.07746345e-01]\n",
      " [-7.45725513e-01 -5.23212850e-01  2.03942329e-01 -4.52158332e-01\n",
      "   3.25441569e-01 -3.06415439e-01 -6.50270700e-01  5.82663119e-01\n",
      "   3.33781928e-01 -5.82649052e-01]\n",
      " [-2.01387599e-01 -2.35011443e-01 -6.23593450e-01  4.73084569e-01\n",
      "   1.67213663e-01  2.27231369e-03 -5.09651639e-02 -5.03676474e-01\n",
      "   2.24918053e-01 -5.21039903e-01]\n",
      " [ 2.56294549e-01 -5.22015512e-01  5.88369146e-02 -3.13004315e-01\n",
      "   2.40446582e-01  5.69245517e-01 -5.80840528e-01 -4.98772562e-02\n",
      "  -3.29063237e-01  7.12186038e-01]\n",
      " [ 1.06194484e+00 -7.65446961e-01 -3.90404820e-01 -4.85837072e-01\n",
      "   8.45566034e-01  3.52378190e-01 -7.32363224e-01 -7.52549589e-01\n",
      "  -2.57105172e-01  8.83924782e-01]\n",
      " [-6.15886711e-02 -5.48547864e-01 -1.04704940e+00 -1.20840058e-01\n",
      "  -5.75482905e-01  5.37624061e-01 -4.14936781e-01  1.12607229e+00\n",
      "   2.53116995e-01 -2.57066250e-01]\n",
      " [ 4.61613154e-03  7.40776122e-01 -9.56688643e-01  9.27067697e-01\n",
      "   4.48191434e-01  3.94145697e-01 -3.16848338e-01 -5.65443575e-01\n",
      "  -3.47554535e-01 -1.15807056e-01]\n",
      " [ 9.46255445e-01 -2.73419768e-01  7.33199596e-01  5.73348165e-01\n",
      "  -3.53635520e-01 -4.71173674e-01  3.66311997e-01  2.66124696e-01\n",
      "   2.96677172e-01  5.12580931e-01]\n",
      " [-7.41800368e-01 -7.58161187e-01 -1.84486344e-01  6.74324557e-02\n",
      "  -2.28922635e-01  1.12863317e-01 -2.56357551e-01 -1.28338289e+00\n",
      "  -2.72737980e-01 -6.32440150e-01]\n",
      " [ 3.20131183e-01  8.55492949e-01  5.16307615e-02  3.73171121e-02\n",
      "  -2.30650425e-01  2.10713834e-01  2.08065212e-01 -4.37265575e-01\n",
      "   2.52903223e-01 -7.07698464e-01]\n",
      " [-5.09865165e-01 -1.75522909e-01  2.27473348e-01 -1.15392208e+00\n",
      "   1.02030747e-01 -6.78763241e-02  3.62745434e-01 -5.15235364e-01\n",
      "   2.74632096e-01 -1.05132982e-01]\n",
      " [-7.05160916e-01 -5.77340662e-01 -7.05138326e-01  7.14031160e-01\n",
      "  -8.00112665e-01 -5.17516509e-02 -3.32077265e-01 -1.53040498e-01\n",
      "   5.65376461e-01  3.67220461e-01]\n",
      " [ 5.21682620e-01  8.82367730e-01 -2.34994695e-01  9.97792035e-02\n",
      "  -3.21281582e-01  1.05924666e+00 -2.79514045e-01 -1.79429948e-01\n",
      "   3.66518319e-01  1.97451964e-01]\n",
      " [-3.63585889e-01  5.87611258e-01 -2.74631083e-01  1.18608139e-02\n",
      "   1.94226131e-01 -6.11977316e-02  9.80609417e-01  6.34933710e-01\n",
      "   1.04708761e-01 -5.66220582e-02]\n",
      " [-5.24343736e-02  2.88667858e-01  5.40888488e-01 -4.07878011e-01\n",
      "  -4.33925778e-01  8.60392392e-01 -4.80572850e-01  2.02507034e-01\n",
      "  -5.44978738e-01 -1.15248255e-01]\n",
      " [ 3.13656121e-01  2.82957107e-01  2.06052914e-01  8.78658220e-02\n",
      "  -6.45199120e-01 -3.08814161e-02  1.33535430e-01 -3.05468857e-01\n",
      "  -6.53947592e-01 -2.59762168e-01]\n",
      " [ 4.45518821e-01  6.90430403e-01  6.60861552e-01 -4.68676507e-01\n",
      "   8.83141831e-02  2.67587036e-01  6.14782274e-01 -1.21176522e-02\n",
      "   8.78975391e-02 -7.40286231e-01]\n",
      " [-9.22405571e-02 -6.76964879e-01 -2.04890296e-01  1.07110357e+00\n",
      "   8.46139550e-01  5.34628689e-01 -7.37434864e-01 -5.09492278e-01\n",
      "  -1.76198466e-03 -1.90973714e-01]\n",
      " [ 5.93382478e-01  3.61701399e-01  5.07569790e-01  3.13920707e-01\n",
      "   1.86841920e-01  6.29370332e-01 -7.25068629e-01 -2.43501347e-02\n",
      "   6.15403891e-01  1.19964862e+00]\n",
      " [-2.95897722e-01  3.52561414e-01  1.64717048e-01  7.36441612e-01\n",
      "   2.40188718e-01 -1.17667139e+00 -2.07084283e-01  6.77233875e-01\n",
      "   8.59170258e-02 -4.90565673e-02]\n",
      " [ 1.05507962e-01 -4.90106255e-01 -3.87226135e-01  9.65491474e-01\n",
      "   9.34703946e-01  7.03851759e-01 -2.87277371e-01  3.78973812e-01\n",
      "   3.95512581e-01 -2.15048984e-01]\n",
      " [ 8.33234072e-01 -1.52827069e-01 -3.66496667e-02 -9.15325880e-01\n",
      "   1.35423315e+00 -9.77969468e-02 -4.59276319e-01  7.57138073e-01\n",
      "  -5.07544041e-01  3.88456345e-01]\n",
      " [ 7.75407553e-01 -6.93331182e-01  1.40115142e-01 -3.59087050e-01\n",
      "  -2.90489823e-01  7.79935539e-01 -1.79337710e-01 -1.18833087e-01\n",
      "  -7.48672962e-01  7.54827142e-01]\n",
      " [-3.47446859e-01 -4.45899479e-02 -2.24999651e-01  1.01390556e-01\n",
      "  -5.28431088e-02 -1.59293115e-01 -5.17395854e-01  4.43469286e-01\n",
      "  -7.34575748e-01  3.25814873e-01]\n",
      " [ 4.57233012e-01 -4.50524092e-02 -4.26129162e-01  8.42806637e-01\n",
      "   1.97982207e-01  1.26027122e-01  6.45577069e-03  1.39368504e-01\n",
      "  -1.94787625e-02  3.27359617e-01]\n",
      " [ 4.28842753e-02  8.55579600e-02 -7.46227086e-01  2.99474329e-01\n",
      "   8.68622243e-01 -1.88199669e-01  6.87655509e-02  7.91690290e-01\n",
      "  -1.89353004e-01 -5.82280196e-02]\n",
      " [ 2.17186123e-01 -2.76687264e-01  1.43235934e+00 -7.15858161e-01\n",
      "  -3.04475904e-01 -2.41014704e-01 -2.56730225e-02  7.90185630e-02\n",
      "  -1.91887887e-03 -6.00652039e-01]\n",
      " [ 2.22282127e-01  3.50438237e-01 -1.00166130e+00  7.42055327e-02\n",
      "  -6.53757393e-01 -4.51589137e-01 -3.22431922e-02  5.35854578e-01\n",
      "  -9.90332961e-01 -9.78271067e-01]\n",
      " [-3.54616404e-01  2.21022025e-01 -2.96967685e-01 -1.88903194e-02\n",
      "  -3.65139395e-01 -7.44967684e-02 -8.10681105e-01  4.55090329e-02\n",
      "  -1.36087656e-01 -7.34365955e-02]\n",
      " [-2.91140467e-01 -1.01517618e+00  4.61475849e-01  1.08795607e+00\n",
      "   9.20864880e-01  6.50477588e-01  1.13932586e+00 -1.14926033e-01\n",
      "  -2.28802599e-02  2.37557605e-01]\n",
      " [-1.69824176e-02  5.98542273e-01 -2.15921104e-01 -7.13474274e-01\n",
      "  -9.25157309e-01 -7.44369984e-01 -5.68380654e-01 -1.01400864e+00\n",
      "   6.94613039e-01  5.67498624e-01]\n",
      " [-3.45907062e-02 -1.26012698e-01 -3.00962836e-01 -5.14968872e-01\n",
      "  -5.37002921e-01 -6.33681178e-01 -5.47549367e-01 -5.07847905e-01\n",
      "  -2.91687369e-01  5.10963500e-01]\n",
      " [-2.67721295e-01 -6.46553874e-01  3.23709488e-01 -9.49289620e-01\n",
      "  -6.71473444e-02  4.62282598e-01 -5.19829810e-01 -1.02320127e-01\n",
      "  -1.85532406e-01  7.89995909e-01]\n",
      " [ 2.64089853e-01  4.13473308e-01  2.21537754e-01 -4.33763832e-01\n",
      "   7.65601993e-01 -1.08639026e+00 -1.39708400e-01  3.18937451e-01\n",
      "   4.07132030e-01 -1.36378527e-01]\n",
      " [ 2.28792485e-02  1.98098183e-01  5.74405611e-01  2.16654807e-01\n",
      "  -4.24004436e-01 -2.80152947e-01 -1.62612069e-02 -2.91145355e-01\n",
      "  -1.61119312e-01  7.02400863e-01]\n",
      " [ 3.93074483e-01 -2.04875261e-01  2.82734752e-01  3.00288975e-01\n",
      "   8.57832655e-02 -1.69351026e-01 -4.91072655e-01 -1.05861999e-01\n",
      "  -3.35094512e-01  1.20239437e+00]\n",
      " [ 1.55443802e-01  5.44403613e-01 -9.38295305e-01  5.78253686e-01\n",
      "   1.86865572e-02 -3.14462215e-01  5.05455844e-02  4.08688724e-01\n",
      "  -1.07100226e-01  4.05043274e-01]\n",
      " [ 5.70677519e-01  5.05417168e-01  2.66828895e-01  1.24911726e-01\n",
      "  -5.10656357e-01 -4.50410455e-01 -1.42068854e-02 -2.36566737e-02\n",
      "  -8.59808266e-01 -1.46248460e-01]\n",
      " [ 3.43287766e-01  5.67686021e-01 -1.30959451e-01 -3.40156645e-01\n",
      "  -6.20896295e-02  4.42048132e-01  7.23377243e-02  3.72522254e-03\n",
      "   2.88134515e-01 -1.36811942e-01]\n",
      " [-7.18855381e-01  2.50035048e-01  3.96204740e-01  1.05731475e+00\n",
      "  -6.20088100e-01 -1.05677712e+00 -1.36430597e+00 -3.22344691e-01\n",
      "   4.31660533e-01  7.44981229e-01]\n",
      " [ 6.53297842e-01 -4.21012610e-01  6.47877231e-02  3.57584685e-01\n",
      "   2.56674558e-01 -6.13314006e-03  3.57499808e-01 -2.52055109e-01\n",
      "   1.35296905e+00 -1.15057409e+00]\n",
      " [-1.28759444e-01 -3.01214457e-01  1.02930181e-01  4.91597384e-01\n",
      "  -4.22708482e-01  1.33862659e-01 -1.16312839e-01  9.90726769e-01\n",
      "  -2.59081185e-01  8.46472025e-01]\n",
      " [ 4.02647048e-01 -4.48059529e-01  1.62469327e+00 -2.77008563e-01\n",
      "   1.66299865e-01 -5.72738424e-02 -6.44588351e-01  7.58505166e-02\n",
      "   9.07369435e-01 -4.36477453e-01]\n",
      " [-1.22269404e+00 -3.82356718e-02 -9.99161378e-02 -1.27683207e-01\n",
      "   1.50840127e+00 -1.11142850e+00 -7.38984719e-02 -7.84474015e-01\n",
      "  -2.84628242e-01  7.06400096e-01]\n",
      " [-5.04239917e-01 -1.41793385e-01  2.79490978e-01  5.21624267e-01\n",
      "   1.54235399e+00 -5.09095490e-01 -2.53061324e-01 -5.33634603e-01\n",
      "  -2.34038904e-01  1.80216655e-01]\n",
      " [ 4.39850301e-01  1.90163255e-01 -2.83909619e-01  2.88553461e-02\n",
      "   1.94170192e-01 -5.12085676e-01 -6.81675732e-01  1.55208968e-02\n",
      "   2.33892947e-02 -6.01359725e-01]\n",
      " [-8.12727213e-01 -1.88835785e-01 -3.46297145e-01  3.26164693e-01\n",
      "   8.14631134e-02 -1.20513606e+00  5.44169188e-01 -9.45740998e-01\n",
      "  -3.80028814e-01  2.38319561e-01]\n",
      " [ 2.66659170e-01  5.29330015e-01 -4.88141805e-01 -9.98411421e-03\n",
      "   7.00459123e-01 -4.38229948e-01  8.74568403e-01  9.71382111e-02\n",
      "  -6.16992295e-01 -4.88195300e-01]\n",
      " [ 1.15173124e-01  3.91911596e-01 -3.12375844e-01 -2.35016048e-01\n",
      "   2.91621149e-01  6.40161753e-01 -5.92793971e-02  9.51396763e-01\n",
      "   3.44606370e-01 -1.89412877e-01]\n",
      " [-2.53952056e-01  3.62470359e-01  1.39304310e-01 -9.68319550e-02\n",
      "   7.77451787e-05  1.56051487e-01 -5.21241486e-01 -1.52200267e-01\n",
      "  -1.24652088e-02  2.08010245e-02]\n",
      " [ 2.96231896e-01  1.44743383e-01 -9.93256345e-02  9.15601671e-01\n",
      "   5.83679259e-01  2.15180606e-01  8.09027731e-01  4.14100587e-01\n",
      "   6.83075070e-01 -2.49084383e-01]\n",
      " [-1.12167038e-01  2.42970616e-01  7.11074293e-01 -8.24452266e-02\n",
      "   3.46565008e-01 -5.50812066e-01  2.25071773e-01  1.05449939e+00\n",
      "  -1.29331219e+00 -1.82686090e-01]\n",
      " [ 2.06179693e-01  5.70095837e-01  1.50565580e-01 -8.25275421e-01\n",
      "   2.33424097e-01 -1.18344498e+00  5.00480354e-01 -2.31557339e-01\n",
      "   4.00635451e-01 -1.47280887e-01]\n",
      " [ 1.64896205e-01 -2.69162375e-02  3.73517126e-01 -8.07119131e-01\n",
      "   3.57168078e-01  5.30133903e-01 -1.58418298e-01  1.26260847e-01\n",
      "  -2.29736686e-01  7.70160973e-01]\n",
      " [-1.20976090e+00  6.34319663e-01  3.60590339e-01 -9.47921947e-02\n",
      "  -1.66250169e-01  1.04895759e+00 -3.83599252e-01  1.72586832e-03\n",
      "  -3.77850741e-01 -8.59587342e-02]\n",
      " [ 2.23647773e-01  9.03173268e-01  9.24481452e-01 -5.76296806e-01\n",
      "   3.42037648e-01 -4.51654643e-01  2.00659975e-01  5.08869231e-01\n",
      "   1.18243682e+00  9.78303421e-03]\n",
      " [-2.84497857e-01  8.42828810e-01 -6.49751246e-01 -4.27445292e-01\n",
      "   4.32653069e-01  1.33609131e-01 -2.72090793e-01 -1.97207645e-01\n",
      "   3.45025271e-01  3.14937919e-01]\n",
      " [ 1.30363166e+00  7.52315879e-01 -4.62616146e-01  4.23419662e-02\n",
      "  -4.11328413e-02  4.53902990e-01 -1.16186655e+00 -1.27727985e+00\n",
      "   2.88574070e-01 -8.65845382e-01]\n",
      " [-8.90304565e-01  1.99010875e-02 -6.27814829e-01 -1.78302795e-01\n",
      "   4.56260681e-01 -1.64665058e-01 -6.47669613e-01  9.11322415e-01\n",
      "  -1.95905760e-01  4.57015216e-01]\n",
      " [ 4.25110191e-01 -8.13038088e-03 -1.12840939e+00 -4.90877539e-01\n",
      "   5.18783629e-01 -1.47436112e-01  7.06559539e-01  2.21840963e-01\n",
      "   7.42660403e-01  1.25844610e+00]\n",
      " [-5.83652928e-02 -8.46024156e-01  1.93162262e-01 -3.59990865e-01\n",
      "  -3.06951612e-01  3.37226510e-01  2.98948854e-01 -6.06726944e-01\n",
      "   6.53443038e-01  2.14083105e-01]\n",
      " [-5.22270799e-01 -3.04170814e-03  2.13232711e-01 -6.69299424e-01\n",
      "   3.91777575e-01  3.17925930e-01  4.15867530e-02  4.31503087e-01\n",
      "   8.30282092e-01  5.80306113e-01]\n",
      " [-1.90611780e-01  7.00713933e-01 -3.25249970e-01 -2.82220747e-02\n",
      "  -4.11792368e-01 -4.78113532e-01 -5.78070395e-02 -2.30771173e-02\n",
      "   8.60235617e-02  4.68395859e-01]\n",
      " [-1.36037374e+00  2.27197841e-01 -2.71187216e-01 -3.00414473e-01\n",
      "   3.90654683e-01  3.58752817e-01 -1.00144529e+00  9.89480019e-01\n",
      "   3.16832602e-01 -5.48309088e-01]\n",
      " [-2.95008212e-01 -1.11312635e-01 -1.05886102e-01 -1.28158733e-01\n",
      "   1.11834455e+00 -3.11105341e-01  3.71616870e-01 -8.62046540e-01\n",
      "   6.11760497e-01  1.29956231e-01]\n",
      " [-6.97395027e-01  3.22836548e-01  9.10596490e-01 -2.83745099e-02\n",
      "   4.93922830e-01  3.59590441e-01 -2.77155250e-01 -4.92810816e-01\n",
      "  -5.55367351e-01 -6.68099165e-01]\n",
      " [-2.50427090e-02 -5.32666147e-01  2.54433155e-02 -3.08429807e-01\n",
      "   6.79491341e-01 -5.63882530e-01 -7.06632555e-01  1.74143851e-01\n",
      "  -5.69626093e-01 -3.81277502e-01]\n",
      " [-2.26942912e-01  1.50551081e-01 -8.03774670e-02 -1.47599921e-01\n",
      "  -6.00620285e-02  6.89174175e-01 -1.46403387e-01  1.43897489e-01\n",
      "  -2.84346610e-01  7.78228566e-02]\n",
      " [-5.56946039e-01  9.36839581e-01  7.98076689e-02 -3.40522714e-02\n",
      "   1.10073186e-01  6.10211372e-01 -2.68962860e-01  3.87459993e-01\n",
      "   2.95739293e-01  4.01620984e-01]]\n",
      "\n",
      "Private components for view 1 (U1):\n",
      " [[ 2.74358451e-01  5.01274526e-01  1.66244075e-01  3.08713149e-02\n",
      "   1.59987003e-01  1.03645399e-02 -2.45756581e-02  2.80153960e-01\n",
      "  -3.86076719e-01  9.93747786e-02  1.79127216e-01 -4.12128210e-01\n",
      "  -1.09836394e-02 -6.72936440e-01 -1.41120046e-01  2.19136193e-01\n",
      "   4.62163121e-01 -2.30637148e-01 -1.79239124e-01 -1.61494583e-01]\n",
      " [-3.53074849e-01 -1.37975216e-01 -5.17319143e-01  2.85917390e-02\n",
      "  -2.39508405e-01  2.11769715e-01  1.43944427e-01  4.70887870e-02\n",
      "   4.85160213e-04  3.53751332e-01  7.09478140e-01 -1.90792345e-02\n",
      "   3.67252827e-02 -2.42674515e-01 -4.35581148e-01 -7.81235695e-02\n",
      "  -5.64991772e-01  1.54478431e-01 -1.29908532e-01 -1.85232103e-01]\n",
      " [ 3.76719177e-01  1.22544035e-01  9.00770545e-01  2.05958903e-01\n",
      "   4.95078057e-01 -4.51450646e-01 -1.30267292e-02  1.89869359e-01\n",
      "   1.27254575e-01  3.32326084e-01  6.29980206e-01 -4.00858790e-01\n",
      "  -7.34970450e-01  5.94760656e-01  1.41987056e-01  3.47725116e-02\n",
      "  -7.67384320e-02  5.10883987e-01 -2.93351620e-01  8.84381868e-03]\n",
      " [-4.33026999e-01 -1.37134343e-01  7.98828676e-02 -6.45292163e-01\n",
      "  -5.27931333e-01 -6.65929556e-01  1.07141718e-01 -6.38241842e-02\n",
      "  -2.31016561e-01 -2.68993974e-02  3.21129620e-01 -1.80377048e-02\n",
      "   4.05430228e-01  4.44940031e-01  4.86176491e-01  2.50167400e-01\n",
      "  -3.60364348e-01 -2.48293668e-01 -6.00030601e-01 -4.54405457e-01]\n",
      " [ 4.26955283e-01 -1.32969886e-01  2.31373072e-01 -2.08202869e-01\n",
      "  -6.71982348e-01 -4.25178379e-01 -1.36131629e-01 -1.38583153e-01\n",
      "   1.46909192e-01  1.12776972e-01 -6.69005141e-02 -6.25313222e-01\n",
      "   5.39866447e-01  4.22450811e-01 -6.92445695e-01  1.05616622e-01\n",
      "  -5.36374971e-02 -4.12862003e-01  6.21156156e-01  1.40474066e-01]\n",
      " [-1.79106351e-02  1.34224415e-01  1.75538048e-01 -1.47681981e-01\n",
      "  -7.17487112e-02  3.71931493e-01  3.68914962e-01 -7.10178986e-02\n",
      "   1.99759617e-01 -2.57002175e-01 -3.78442049e-01  5.41242182e-01\n",
      "  -2.96724290e-01  5.59693098e-01 -2.13400409e-01  3.54187220e-01\n",
      "   4.33820873e-01 -3.35670382e-01 -1.87522903e-01 -2.49837786e-01]\n",
      " [-3.74815792e-01 -4.34139222e-01 -1.73105635e-02  2.41566062e-01\n",
      "  -8.07841681e-03  5.07434726e-01  1.65916577e-01 -5.43358564e-01\n",
      "  -2.96137810e-01  4.28087115e-01  7.25847721e-01 -3.26374829e-01\n",
      "   2.18728140e-01  9.37085971e-02  9.88528967e-01 -4.54571769e-02\n",
      "   5.64942718e-01 -3.79730761e-01  2.02960260e-02 -4.86534923e-01]\n",
      " [-2.69208819e-01  6.41357377e-02  2.19040319e-01  3.00870091e-01\n",
      "   2.14548856e-01  9.95223224e-03 -5.96715689e-01 -2.01770544e-01\n",
      "  -1.06465042e-01 -4.29835469e-01  5.01137674e-01 -4.79415059e-02\n",
      "   2.65677214e-01 -5.04393518e-01 -1.10745460e-01 -4.66946125e-01\n",
      "  -2.05877408e-01 -5.26121669e-02 -1.22221753e-01 -1.19905673e-01]\n",
      " [ 6.50938749e-01  1.30262241e-01 -2.61160016e-01  6.25579178e-01\n",
      "  -3.27596813e-02  2.52119958e-01  1.11775436e-01 -4.44597006e-01\n",
      "   9.22544897e-02  8.67588166e-03  2.52504319e-01  1.21123968e-02\n",
      "   2.59557404e-02  1.67533502e-01  1.20638594e-01  3.13137360e-02\n",
      "  -3.26653481e-01  2.19829276e-01 -3.34440649e-01  7.94095516e-01]\n",
      " [-4.33275253e-01  9.77987424e-02 -6.44394279e-01  3.04275483e-01\n",
      "  -1.42682970e-01 -8.87693524e-01  3.98995638e-01 -2.90933460e-01\n",
      "   1.76103771e-01  1.11895494e-01 -3.51846337e-01 -3.43346179e-01\n",
      "  -3.11095327e-01  8.90916809e-02  6.70349821e-02  1.09308138e-01\n",
      "  -3.04559529e-01  6.81817234e-01 -6.15258276e-01 -4.37515199e-01]]\n",
      "\n",
      "Private components for view 2 (U2):\n",
      " [[ 0.475184    0.39069173  0.74537     0.0325001   0.2563811  -0.95900327\n",
      "   0.7255904   0.09334754 -0.1873166   0.12376648  0.4167923  -0.48814106\n",
      "   0.5230796  -0.40359566 -0.04182201 -0.09157947 -0.34386727 -0.27541548\n",
      "  -0.74533707  0.10487323 -0.3379255  -0.46350646  0.37145033 -0.06738683\n",
      "   0.28038856 -0.36588842  0.5357769  -0.9680797  -0.27944237 -0.40057734]\n",
      " [ 0.62122685 -0.28698736 -0.30437517 -0.49392152 -0.3904471  -0.32432723\n",
      "   0.6405664  -0.5240928  -0.30450895  0.24102695 -0.8317327  -0.09235328\n",
      "   0.22507049  0.20240648 -0.1996962   0.09461658  0.09796294 -0.21697238\n",
      "  -0.4836366  -0.35706115  0.34617224  0.31287107  1.0000831   0.08483175\n",
      "  -0.5679724   0.41974267  0.54460406  0.48667055  0.43951347  0.38434267]\n",
      " [ 0.4071756   0.35560054  0.1606508  -0.07277458 -0.12362998  0.24690695\n",
      "   0.07817028 -0.07541022  0.4497302   0.36171374  0.0860478   0.4208072\n",
      "  -0.7006627   0.4782874   0.3024658  -0.48396876  0.5006714   0.23660174\n",
      "  -0.6623964  -0.24284156  0.26545042  0.05075197  0.19403994  0.6585591\n",
      "   0.08758133  0.06484333 -0.05202792  0.08584269 -0.4983925   0.2041032 ]\n",
      " [ 0.3594133  -0.53676474 -0.16692957  0.32561922  0.47144824 -0.26559097\n",
      "   0.28073692 -0.08778546  0.64191395 -0.35770264 -0.42633024 -0.44874513\n",
      "  -0.42865965 -0.02866184  0.36462802  0.37772465  0.2586662   0.70204395\n",
      "   0.07253268 -0.19957009  0.49019325 -0.3979637   0.02521493 -0.3448777\n",
      "   0.2701251  -0.3831927  -0.19953579 -0.62064344  0.24317665 -0.0031101 ]\n",
      " [-0.72627485 -0.69710416  0.71684563  0.12939768  0.3689547  -0.07670294\n",
      "   0.32712713  0.03056575 -0.17614616  0.5579918   0.2826326   0.08364372\n",
      "  -0.68760556  0.47690058  0.22040522  0.4811172  -0.46183458 -0.33524337\n",
      "  -0.3306605  -0.08117032  0.20756458  0.32938644  0.1766305   0.26231936\n",
      "   0.11839718  0.48942903 -0.08778571 -0.22118312  0.24368528 -0.1003256 ]\n",
      " [-0.6009687   0.07941006  0.22730125  0.31035903 -0.6884603  -0.32040465\n",
      "   0.74809796  0.32434115  0.22131889 -0.44490385  0.5331039   0.2541253\n",
      "   0.32424     0.11145266 -0.23324141 -1.1432292  -0.11964688  0.33997113\n",
      "  -0.190366   -0.42201608  0.4176245   0.11837745  0.5445054  -0.088597\n",
      "   0.19771266 -0.4081176  -0.40818867  0.1866439   0.71240985  0.2645968 ]\n",
      " [-0.36869407 -0.2942624   0.20315331  0.4902843   0.17585947  0.26477516\n",
      "  -0.33271486 -0.07126294 -0.19824135 -0.29097843  0.27022097  0.778278\n",
      "  -0.36376795  0.29841003 -0.61505175  0.05353995  0.29592368 -0.11450116\n",
      "  -0.38830316  0.06486871 -0.55530643  0.21272664  0.51403034 -0.2907556\n",
      "  -0.04159508 -0.3165018   0.3107458   0.1343229  -0.06467833 -0.6854589 ]\n",
      " [-0.36274096  0.25691882  0.10951561  0.5531847   0.73547775 -0.02112871\n",
      "  -0.03954547 -0.23490052  0.15701836 -0.46002936 -0.34866008 -0.35226828\n",
      "  -0.43403825 -0.24032198  0.59210986 -1.0407676  -0.31023714 -0.42182449\n",
      "  -0.08957724  0.17900215  0.00594536 -0.61129636  0.29672754  0.42843243\n",
      "   0.23420279  0.5750331  -0.274433    0.58931726  0.44115388 -0.00433496]\n",
      " [ 0.31526625 -0.5398863   0.06734678 -0.01085049  0.30508068 -0.2333562\n",
      "   0.1832357   0.02144506  0.5256703  -0.42489797  0.25828195  0.5094171\n",
      "   0.4220584   0.4945828  -0.76340413  0.45533353 -0.29091588 -0.69599867\n",
      "   0.15030757  0.29347318  0.6219417  -0.97946286  0.39642254  0.15972294\n",
      "  -0.14919992 -0.04624671 -0.69823337 -0.04086987 -0.41647145  0.06481261]\n",
      " [-0.6225377  -0.5368253   0.11949413 -0.43023407 -0.09313001  0.28214434\n",
      "  -0.03950283 -0.00687586  0.43216133  0.12242334 -0.27840084  0.17756177\n",
      "   0.52822274  0.61608946  0.00932851 -0.7550264  -0.426162   -0.5223351\n",
      "   0.21384652  0.06181205 -0.44400054  0.18442541 -0.3400392   0.30265972\n",
      "   0.39460704 -0.0816045   0.61909956 -0.54316056  0.1599621  -0.2249221 ]]\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MOFA(nn.Module):\n",
    "    def __init__(self, num_samples, num_features1, num_features2, num_factors):\n",
    "        super(MOFA, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.num_features1 = num_features1\n",
    "        self.num_features2 = num_features2\n",
    "        self.num_factors = num_factors\n",
    "        \n",
    "        # Initialize shared latent factors\n",
    "        self.S = nn.Parameter(torch.randn(num_samples, num_factors) * 0.01)\n",
    "        \n",
    "        # Initialize private latent factors for each view\n",
    "        self.U1 = nn.Parameter(torch.randn(num_factors, num_features1) * 0.01)\n",
    "        self.U2 = nn.Parameter(torch.randn(num_factors, num_features2) * 0.01)\n",
    "\n",
    "    def model(self, X1, X2):\n",
    "        # Priors\n",
    "        S_prior = dist.Normal(torch.zeros(self.num_samples, self.num_factors), torch.ones(self.num_samples, self.num_factors)).to_event(2)\n",
    "        U1_prior = dist.Normal(torch.zeros(self.num_factors, self.num_features1), torch.ones(self.num_factors, self.num_features1)).to_event(2)\n",
    "        U2_prior = dist.Normal(torch.zeros(self.num_factors, self.num_features2), torch.ones(self.num_factors, self.num_features2)).to_event(2)\n",
    "        \n",
    "        # Sample from priors\n",
    "        S = pyro.sample('S', S_prior)\n",
    "        U1 = pyro.sample('U1', U1_prior)\n",
    "        U2 = pyro.sample('U2', U2_prior)\n",
    "        \n",
    "        # Likelihood\n",
    "        X1_hat = torch.matmul(S, U1)\n",
    "        X2_hat = torch.matmul(S, U2)\n",
    "        \n",
    "        with pyro.plate('data1', X1.shape[0]):\n",
    "            pyro.sample('obs1', dist.Normal(X1_hat, 0.1).to_event(1), obs=X1)\n",
    "        \n",
    "        with pyro.plate('data2', X2.shape[0]):\n",
    "            pyro.sample('obs2', dist.Normal(X2_hat, 0.1).to_event(1), obs=X2)\n",
    "\n",
    "    def guide(self, X1, X2):\n",
    "        # Variational distributions\n",
    "        S_loc = pyro.param('S_loc', torch.randn(self.num_samples, self.num_factors) * 0.01)\n",
    "        S_scale = pyro.param('S_scale', torch.ones(self.num_samples, self.num_factors) * 0.1, constraint=dist.constraints.positive)\n",
    "        U1_loc = pyro.param('U1_loc', torch.randn(self.num_factors, self.num_features1) * 0.01)\n",
    "        U1_scale = pyro.param('U1_scale', torch.ones(self.num_factors, self.num_features1) * 0.1, constraint=dist.constraints.positive)\n",
    "        U2_loc = pyro.param('U2_loc', torch.randn(self.num_factors, self.num_features2) * 0.01)\n",
    "        U2_scale = pyro.param('U2_scale', torch.ones(self.num_factors, self.num_features2) * 0.1, constraint=dist.constraints.positive)\n",
    "        \n",
    "        S_dist = dist.Normal(S_loc, S_scale).to_event(2)\n",
    "        U1_dist = dist.Normal(U1_loc, U1_scale).to_event(2)\n",
    "        U2_dist = dist.Normal(U2_loc, U2_scale).to_event(2)\n",
    "        \n",
    "        pyro.sample('S', S_dist)\n",
    "        pyro.sample('U1', U1_dist)\n",
    "        pyro.sample('U2', U2_dist)\n",
    "\n",
    "# Example usage:\n",
    "num_samples = 100\n",
    "num_features1 = 20\n",
    "num_features2 = 30\n",
    "num_factors = 10\n",
    "num_iterations = 2000\n",
    "\n",
    "# Generate synthetic data\n",
    "X1 = torch.randn(num_samples, num_features1)\n",
    "X2 = torch.randn(num_samples, num_features2)\n",
    "\n",
    "# Initialize the model\n",
    "model = MOFA(num_samples, num_features1, num_features2, num_factors)\n",
    "\n",
    "# Setup the optimizer and the inference algorithm\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model.model, model.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Train the model and log loss\n",
    "losses = []\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(X1, X2)\n",
    "    losses.append(loss)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i} : loss = {loss:.4f}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "# Get the learned latent factors\n",
    "S_posterior = pyro.param(\"S_loc\").detach().numpy()\n",
    "U1_posterior = pyro.param(\"U1_loc\").detach().numpy()\n",
    "U2_posterior = pyro.param(\"U2_loc\").detach().numpy()\n",
    "\n",
    "print(\"Shared components (S):\\n\", S_posterior)\n",
    "print(\"\\nPrivate components for view 1 (U1):\\n\", U1_posterior)\n",
    "print(\"\\nPrivate components for view 2 (U2):\\n\", U2_posterior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 284461.6369\n",
      "Step 100 : loss = 128097.0005\n",
      "Step 200 : loss = 111385.5440\n",
      "Step 300 : loss = 110100.7861\n",
      "Step 400 : loss = 109631.2777\n",
      "Step 500 : loss = 109369.3999\n",
      "Step 600 : loss = 109292.5444\n",
      "Step 700 : loss = 109184.3082\n",
      "Step 800 : loss = 109223.9327\n",
      "Step 900 : loss = 109214.8637\n",
      "Step 1000 : loss = 109178.8585\n",
      "Step 1100 : loss = 109195.4989\n",
      "Step 1200 : loss = 109233.9718\n",
      "Step 1300 : loss = 109227.2623\n",
      "Step 1400 : loss = 109224.8215\n",
      "Step 1500 : loss = 109218.5009\n",
      "Step 1600 : loss = 109205.0811\n",
      "Step 1700 : loss = 109218.1890\n",
      "Step 1800 : loss = 109223.8119\n",
      "Step 1900 : loss = 109197.0287\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared components (S):\n",
      " [[ 0.270202    0.324543   -0.11763763 -0.18171152  0.71666175 -0.46586946\n",
      "   0.5080538  -0.6446638  -0.02063875 -0.35092515]\n",
      " [-0.6703211  -0.00394398 -0.506512   -0.8647218   0.6869167   0.40876272\n",
      "   0.42830703  0.42904523 -0.59121263 -0.10258424]\n",
      " [ 0.5656179  -0.42971876  1.1416957   0.6088184   0.6378151  -0.32124695\n",
      "   0.34172437 -0.0492017  -0.28286263  0.99139327]\n",
      " [-0.61353105  0.016013    0.09893162  0.3065984  -1.149986    0.43462688\n",
      "  -0.27717155 -1.0378842   0.80110544  1.1773438 ]\n",
      " [ 0.25696725  0.05606     0.12766148  0.59383655 -0.2125626  -1.3022519\n",
      "   0.05657695  1.5015812   0.20898569 -0.46292433]\n",
      " [ 1.0357586  -0.5954201   0.15558797  0.39823076  1.0237004   0.35263243\n",
      "  -0.50622046 -0.32096902  0.5001128  -0.22347446]\n",
      " [ 0.13707104 -0.14043799  0.5510203  -0.23831147 -0.5194199  -0.06018124\n",
      "   0.8968282   0.05756795 -0.00446774 -0.4054764 ]\n",
      " [ 0.4018113   0.3141261   0.22824551 -1.1143539   0.19328907  0.33778253\n",
      "   0.4836785  -0.42861053  0.10052133  0.06766693]\n",
      " [-0.49779952 -1.2410096   0.00916677 -0.41404393 -0.34078076  0.8351228\n",
      "   0.06348351 -0.8418551  -0.9035171  -0.4689593 ]\n",
      " [-0.20815797 -0.7066417   0.5231461   0.36036077  0.17364764  1.2323785\n",
      "  -0.08995716 -0.42574862  0.8576009  -0.4193612 ]\n",
      " [-0.02438024  0.00611911  0.5375541   0.35037115  0.78445214 -0.03208277\n",
      "  -1.6800374  -0.34217864  0.6809468   0.24000011]\n",
      " [ 0.2944594   0.06817286 -0.2664306  -1.2010522  -0.00272083  0.14660768\n",
      "  -0.28460756 -0.11666415  0.33574015  0.4481004 ]\n",
      " [ 0.02060758 -0.59095293  0.06702848 -0.34539837 -1.2389747  -0.72253704\n",
      "  -0.6833855  -1.4776268  -0.03096295 -0.4890288 ]\n",
      " [-1.3789116   0.12802215  0.27804732 -0.17798315 -0.07889814  0.02086088\n",
      "   1.1525973   0.27874565  0.18026951 -0.85886157]\n",
      " [-0.06757764  0.5421059   0.31264865 -0.6169086   0.48233688 -0.25672433\n",
      "  -0.6665254  -0.66717535 -0.6406148   0.2714833 ]\n",
      " [-0.5973177   0.9803212  -0.85996664 -0.5140505  -0.32237458  0.4294812\n",
      "   0.5268536  -0.4162876  -0.01742741 -0.13148254]\n",
      " [-0.6130921   0.10226636  0.8936566  -0.07127727  0.49925297 -0.0501809\n",
      "  -0.30378932  0.23857155  0.4431451  -0.12090744]\n",
      " [-0.16302194 -0.49887022 -0.51018775 -0.94726884  0.02403315 -0.34169823\n",
      "   0.7073546  -0.22463834  0.48344305 -0.00493685]\n",
      " [-0.35193062  0.95151585 -0.36415473  0.01818028  0.38548082 -0.40796533\n",
      "   0.16015121  0.00910942 -0.02118628 -0.490018  ]\n",
      " [ 0.12618856  0.6041275  -0.14679107 -0.16215317 -0.00906495  0.87030375\n",
      "  -0.13849345  0.69619423  0.13381977 -0.3011358 ]\n",
      " [-0.07985374 -0.37003875  0.81922674 -0.6803305  -1.4315686  -0.23390147\n",
      "  -0.2740875   1.0592259  -0.20413798 -0.24909918]\n",
      " [-0.30470192 -0.209506    1.008691    0.17754352  0.3145415   0.75235397\n",
      "   0.23711231 -0.02835199  0.19970287 -0.4314258 ]\n",
      " [ 1.0269403   1.1104329   1.5349202  -0.7454884  -0.41303283  0.4220909\n",
      "   0.17892258  0.24992839  0.63344824 -0.1808884 ]\n",
      " [ 0.04473048  0.41802728  0.507823   -0.30960345  0.22430585 -0.74305874\n",
      "  -0.66126645 -0.8101172  -0.5095067  -0.97336334]\n",
      " [-0.1398635   0.8074296  -0.628553    0.8900515  -0.08467319  0.830233\n",
      "   0.13954037  0.6266076   0.37202975  0.5727191 ]\n",
      " [ 0.21471596  0.7648448   0.2768228   0.9749179   0.42677426  0.8814112\n",
      "  -0.6977096  -1.1947287  -0.78041464  0.36410454]\n",
      " [ 0.40100938  0.5982138   0.23210028 -0.64587295 -0.12711802  0.31332293\n",
      "  -0.27344403  0.43357065 -0.39014983  0.5453816 ]\n",
      " [ 0.94853026  0.46503276 -0.02164644  0.5083768   0.88986546 -0.18125105\n",
      "   0.89012223  0.23234157  0.25522667 -0.40643004]\n",
      " [-1.0988942  -0.08025213  0.56143075 -0.27752388  1.1471727   0.04918037\n",
      "  -0.6730999   1.4693072   0.5138109   0.8253022 ]\n",
      " [ 0.7478341   0.24372996 -0.52022386 -0.12614879 -0.11301421 -0.08195152\n",
      "  -0.19225392 -0.13609114  0.63045025  0.11273206]\n",
      " [-0.540117   -0.35733664  0.49251217 -0.20875266 -0.55667585 -0.58694685\n",
      "  -0.25429234  0.25250694  0.39774993 -1.2415382 ]\n",
      " [-0.37355125 -0.43144068 -0.21267366 -0.21455269 -0.18284331  1.1495161\n",
      "  -0.15192914 -0.5032125  -0.57299876  0.17588645]\n",
      " [-0.63498276 -0.49346203 -0.01519273  0.97920585  0.17115082  1.0085567\n",
      "   0.28404534  0.19737186 -0.59194404  0.12865451]\n",
      " [-0.450293   -0.40512827  0.44660708  0.04825573 -0.28655642  0.32024127\n",
      "  -0.6973857  -0.05790133 -1.4016104   0.15591154]\n",
      " [-0.75223756 -0.06185508  0.9558847  -0.03274013  0.41582948  0.04390652\n",
      "   0.8386962  -1.0069654  -0.07970154  0.44430193]\n",
      " [ 0.5892777   0.20712784  0.5408177  -0.44234797  0.51396227  0.6007937\n",
      "   0.56225234 -0.5401307   0.28933442  0.96405196]\n",
      " [-1.364608    0.44539395 -0.30065173 -0.00879768  1.0103258   0.0252319\n",
      "   0.23631895 -0.15327223 -0.08749645  0.3522629 ]\n",
      " [ 0.84918743 -0.9513915  -0.23452549 -1.2134904   0.07915571 -0.4297023\n",
      "  -0.65541816 -0.3024907   0.5206702   0.6725081 ]\n",
      " [-0.01688563 -0.18701777 -0.165155   -0.2613702  -0.24716303  0.30383354\n",
      "   1.0178237  -0.35940406  0.34085426 -1.090738  ]\n",
      " [ 0.20832735 -0.40388533 -0.1052985  -0.60275656  0.29733023  0.00648498\n",
      "   0.26526967  0.5381818  -0.7634123  -0.22415474]\n",
      " [ 0.5602912  -0.10060658  0.21041508 -0.29971915 -0.5996422   0.0245369\n",
      "  -0.5797586  -0.0488041   1.0155932   0.5930995 ]\n",
      " [ 0.10807265 -0.7478825   0.38176095  0.29609242 -0.57221913  0.441706\n",
      "   0.08571601  0.96655357  0.01449464 -0.1101043 ]\n",
      " [-0.3415202   0.28538474  0.554417    0.1859736  -0.5870264   0.6193955\n",
      "   0.01343582 -0.9356895   0.06290911 -1.0261337 ]\n",
      " [-0.6756321   0.5301577  -0.5940888  -0.7773917   0.7081547   0.26954946\n",
      "   0.7077447  -0.2536624   0.73528737 -0.37741256]\n",
      " [ 0.32684243 -0.6208378   0.66531354 -0.6414159   0.27196667  1.0499272\n",
      "  -0.47483578 -0.08772909 -0.01123193  0.543278  ]\n",
      " [-1.3418396  -0.9270446   0.35974503 -0.01432343  0.5650194   0.02216118\n",
      "   0.1435477  -0.38210365 -0.10638084  0.39653847]\n",
      " [ 0.37478295 -0.16219793  0.58260286  0.9392211   0.7075527   0.17745338\n",
      "   0.4721536   0.93539363 -0.8043073  -0.24066092]\n",
      " [-1.170301    1.1647598  -0.07961734 -0.9704891  -0.6056373  -1.4679862\n",
      "   0.1840133  -0.34379032 -0.24168473  0.5241332 ]\n",
      " [ 0.17618954 -0.09023861  1.3649873   0.33545747  0.7069578  -0.189787\n",
      "  -0.08173858 -0.32964134  0.12850705  0.03279815]\n",
      " [-0.09924771  0.8022405   0.75623953 -1.0345297  -0.21049047 -0.8638526\n",
      "   0.0732246   0.13285677 -0.37367633  0.5721687 ]\n",
      " [ 0.20532107  0.04063448  0.2761983   0.26909035  0.12645522  0.27361813\n",
      "   0.82682467  0.17836581 -0.986866   -0.5491392 ]\n",
      " [ 0.42590752  1.0104417  -0.11263968  0.57465655 -0.4688254   0.14936677\n",
      "  -0.8781362  -0.38233373 -0.985872    0.05263038]\n",
      " [-0.04839561  0.6503418   0.64008886  0.2615027  -0.5606918   0.71334773\n",
      "  -0.51244766  0.23943377  0.19132647 -0.8913632 ]\n",
      " [-0.22262403 -0.53178    -0.26356056 -0.18472925  1.5461035   0.36076576\n",
      "  -1.1476519   0.32932994  0.5791572  -0.6379025 ]\n",
      " [ 1.5612689  -0.40174893 -0.14520018 -0.05656949  0.783649   -0.432836\n",
      "   1.0333214  -0.5874003  -0.88712627  0.13684362]\n",
      " [-0.18296097 -0.19248661  0.4462684  -0.02547551 -0.01549842 -0.59767294\n",
      "  -0.79262185  0.27931508 -0.9471375   0.4297325 ]\n",
      " [-0.6680503   0.11056618  0.58628     0.13235207 -0.6870085  -0.2825614\n",
      "  -0.7438999   1.2612365   0.47859222 -0.33202404]\n",
      " [-1.1177578  -0.32765323 -1.1671838  -0.10377577 -0.05961587  0.23157182\n",
      "  -0.8611905   0.5526546  -0.11885814 -0.05229821]\n",
      " [ 0.21733022  0.38356525 -0.344925   -0.5760946   0.2653591   0.49969372\n",
      "  -0.46859518  0.2355297  -0.0359875  -1.3242489 ]\n",
      " [ 0.03091727 -0.95332986  0.3759857   0.06469711 -0.36389694 -0.7713408\n",
      "   1.0183551  -0.49375704  0.9782649   0.3216707 ]\n",
      " [ 1.0810678   0.08180454 -0.20409411 -0.93923163  0.16969284  1.1704589\n",
      "  -0.19714852 -0.41302195  1.0604624  -0.658842  ]\n",
      " [-0.5463145  -0.12157333  0.4963154   0.01437674 -0.5906575   0.6492899\n",
      "   0.14101918  0.39080164  0.09631293 -0.6516562 ]\n",
      " [-0.1489842   0.04143966  0.5910865   0.30749854  0.2485302  -0.5784421\n",
      "  -0.360826   -0.12209763  0.64293325 -1.326676  ]\n",
      " [ 0.5220213  -0.7157748  -0.8862193   1.4724364  -0.93494165  0.29465583\n",
      "   0.28284925  0.22567819  0.4685169   0.43746576]\n",
      " [ 0.41812885 -0.14204656  0.12648278 -0.4496274   0.09585578 -0.4323785\n",
      "  -0.27080032  0.81879574 -0.20068555  1.3545103 ]\n",
      " [-0.31101534 -1.1002703   0.24725953 -0.7320592   0.5496622  -0.2762648\n",
      "   0.6050202  -0.02016789 -0.5631664   0.23634256]\n",
      " [ 0.2844079  -0.44879216 -0.34759378  0.2102957   0.46939486 -0.66873753\n",
      "  -0.4452724  -0.0647496   0.9685135   0.23134577]\n",
      " [-0.15257375 -0.2188246   0.20085877  0.30313772  0.04510242  0.45492107\n",
      "   0.58752793  0.5437704  -0.37564978  0.80749315]\n",
      " [ 0.50252485  0.8109574   0.9613816  -0.47901693 -0.03626661  0.7334458\n",
      "   0.02161744  0.44078547  0.4049526   0.03984741]\n",
      " [ 0.6956096  -1.0652478   0.15476811 -0.82141256  0.21084815  0.22440349\n",
      "   0.09969077  0.9659038  -0.3291987  -0.23180531]\n",
      " [-0.3288265  -0.15894485  0.3263509   0.48533922  0.5870005  -0.96581036\n",
      "   0.2818772  -0.53333044  0.72608244 -0.26692268]\n",
      " [-0.5151452   0.36349705  0.79978466  0.39787754 -0.88849986  0.614092\n",
      "   0.62834007  0.12369145  0.7694972   1.091021  ]\n",
      " [ 0.01960363  0.31879503 -0.12430672  0.07591617 -0.70328194  0.03375605\n",
      "  -0.03811923  0.13291785 -1.0547525  -0.71200836]\n",
      " [ 0.33624932  0.35211927  0.35974938  0.11810159 -0.5236861  -0.04998016\n",
      "   1.0305649   0.1606719  -0.83885145  0.49441156]\n",
      " [ 0.24804962 -0.95171034  0.56359124  0.40979266 -0.34136248 -0.15625514\n",
      "  -0.36400685 -0.34985328 -0.47354954 -0.94504327]\n",
      " [-0.24031386 -0.6192991   0.13461006 -0.11307945 -0.6699342  -0.14197868\n",
      "   0.3665941  -0.49309358  0.3636244   0.24155167]\n",
      " [-0.7924303   0.21502547  0.2887608   0.55859846  0.8616906  -0.46295202\n",
      "   0.22095473 -0.1676443   0.29362392  0.06866092]\n",
      " [ 0.283986   -0.14983219  0.39059272 -1.1980153   0.11433511  0.73572105\n",
      "  -0.851342    0.62488943 -0.1675506  -0.61228174]\n",
      " [-0.41840503 -0.25877795 -0.159202    0.0246789   0.27116838 -0.1445323\n",
      "   0.17345244  0.5807325  -0.14285631  0.5763244 ]\n",
      " [ 1.096072   -0.2426716  -0.17715384 -0.18915947 -0.57696867 -0.08480443\n",
      "  -0.18334039  1.0592582   0.84353006  0.8104461 ]]\n",
      "\n",
      "Private components for view 1 (U1):\n",
      " [[-6.70861781e-01  8.28104496e-01 -7.01554585e-04  4.35586154e-01\n",
      "   2.11300328e-01 -8.34583119e-02 -8.39466095e-01 -7.99615324e-01\n",
      "  -4.82693553e-01  1.10217482e-01  3.00214678e-01 -3.12688768e-01\n",
      "   1.34407565e-01 -1.52756661e-01 -1.52953938e-01  9.60551798e-02\n",
      "  -5.07198870e-01 -3.45139474e-01  2.12945566e-01  6.06472313e-01]\n",
      " [-4.56422269e-01 -9.27229412e-03 -9.84206982e-03  1.47295251e-01\n",
      "  -7.37860620e-01 -3.94446999e-02 -9.76840556e-02 -5.16344070e-01\n",
      "   4.05044943e-01 -2.69552171e-01 -9.19255093e-02  9.10516739e-01\n",
      "   3.29309016e-01 -1.35974362e-01 -2.03373954e-01 -1.83992669e-01\n",
      "   4.09437239e-01 -1.17075831e-01  7.04754114e-01  2.75397897e-01]\n",
      " [ 7.65224174e-02  1.60020202e-01 -3.98283601e-01  2.29140650e-02\n",
      "  -3.03166568e-01 -5.44095159e-01 -3.03448260e-01 -6.06135540e-02\n",
      "   7.13913620e-01  1.32557288e-01  3.95602643e-01 -2.23887414e-01\n",
      "   4.05204326e-01 -3.97343487e-02  5.55214107e-01  2.25442693e-01\n",
      "   3.42271030e-01  3.08844030e-01 -8.64098728e-01  1.15108892e-01]\n",
      " [-1.23981103e-01  3.87884229e-01  5.28998196e-01 -1.64543111e-02\n",
      "   7.68120261e-03 -4.53053772e-01  4.66102064e-01 -4.36794966e-01\n",
      "   2.99707115e-01  1.07680011e+00  3.68557245e-01 -1.01085948e-02\n",
      "   3.16186935e-01 -3.14191222e-01  5.26816964e-01 -2.47800380e-01\n",
      "  -9.49080139e-02 -7.10199654e-01  2.64729023e-01 -5.95628858e-01]\n",
      " [ 1.51344389e-01  2.37264395e-01 -3.66699160e-03  4.42790806e-01\n",
      "  -3.49321336e-01 -8.59023333e-01 -2.89282411e-01  6.47581458e-01\n",
      "   2.21217170e-01 -5.93266338e-02  7.55118206e-02  4.42754388e-01\n",
      "   5.87602377e-01 -9.83067527e-02  3.70706350e-01  5.12918197e-02\n",
      "  -5.81435598e-02 -3.23446095e-01  4.48501050e-01  5.34403743e-03]\n",
      " [-8.27092454e-02  1.17288105e-01 -4.12504882e-01 -2.28831336e-01\n",
      "   6.91628754e-02 -5.16674280e-01  3.61619651e-01 -5.11109531e-01\n",
      "   3.03197891e-01  1.15232423e-01 -4.58545715e-01 -1.13107570e-01\n",
      "  -3.07343714e-02  4.69825745e-01  8.79813656e-02 -1.74748793e-01\n",
      "   1.03210405e-01 -1.71778753e-01 -4.49608751e-02  4.26967107e-02]\n",
      " [ 1.17252745e-01 -1.99548572e-01  3.93182226e-03  4.19327646e-01\n",
      "  -1.59188479e-01  5.14406860e-01  1.95750520e-01 -3.55787179e-03\n",
      "   1.19283341e-01  7.73885399e-02 -2.43102834e-01  4.97218549e-01\n",
      "   6.07392967e-01  1.23042859e-01 -4.56339270e-01 -1.73548654e-01\n",
      "  -5.61735593e-02 -7.37574399e-01 -6.29315972e-01  1.79054350e-01]\n",
      " [-3.92083347e-01  4.18244034e-01  4.04036194e-01 -3.50158036e-01\n",
      "  -1.75028026e-01  4.97349352e-01 -9.36819166e-02  6.65209711e-01\n",
      "   7.78896153e-01 -3.23560718e-03  4.49717157e-02 -1.02013387e-01\n",
      "   1.84205845e-01  8.95464540e-01 -2.72347420e-01 -4.50352430e-02\n",
      "  -2.26294361e-02  4.71774489e-02  3.06217730e-01 -7.20700845e-02]\n",
      " [ 4.78516012e-01 -3.98153998e-02  1.12537660e-01 -1.31032854e-01\n",
      "   3.98994833e-01  1.80117056e-01  1.58012286e-01 -9.87068117e-02\n",
      "  -2.24321485e-01 -4.73387502e-02  2.57566541e-01 -2.09491439e-02\n",
      "  -4.59040374e-01 -4.21795994e-01 -4.24552858e-02  2.55563498e-01\n",
      "  -4.85262066e-01 -1.24417052e-01 -1.05449855e-02  7.42711872e-02]\n",
      " [ 1.01376235e+00 -1.32518569e-02 -1.13169529e-01  4.41004992e-01\n",
      "  -2.58701265e-01 -1.48036391e-01  1.27366021e-01  2.42447183e-01\n",
      "   2.71985054e-01 -1.31416440e-01  4.28066328e-02 -2.08629183e-02\n",
      "  -5.12713753e-02 -1.53046474e-01 -4.90508437e-01  1.65860996e-01\n",
      "   1.11515850e-01 -3.35168511e-01 -1.31197497e-01  8.61360803e-02]]\n",
      "\n",
      "Private components for view 2 (U2):\n",
      " [[-0.14022212  0.17815085  0.23196104 -0.1393517   0.603286    0.7054751\n",
      "  -0.24356566  0.23976721  0.16918483  0.41890416 -0.03379175 -0.39665765\n",
      "   0.05971564 -0.10599655 -0.25340337  0.68944424  0.0422756  -0.390798\n",
      "   0.15970309 -0.11293876  0.00750285 -0.25549412  0.04750983  0.45192358\n",
      "   0.4843529   0.63552386  0.19445416 -0.26304987  0.20119183  0.24317203]\n",
      " [-0.14184442  0.162244   -0.31985202  0.8065802   0.5126867   0.04229149\n",
      "   0.6646436   0.67764395 -0.0300646  -0.25477496  0.1642609  -0.00432906\n",
      "  -0.6150214  -0.07759555  0.55365676 -0.11209376 -0.09307931  0.31219697\n",
      "  -0.26534256  0.33967787  0.09250721  0.01489133 -0.2524091  -0.02507099\n",
      "   0.3400203  -0.4515818  -0.31736547  0.5351161   0.3945702   0.19623365]\n",
      " [-0.72062725 -0.04671154  0.35481933 -0.34052828  0.14501947 -0.10000608\n",
      "  -0.46538287  0.7629329   0.04640588 -0.16195364  0.12584749 -0.46923846\n",
      "   0.4242219  -0.09052238 -0.00463277 -0.8356631  -0.32123107  0.40711972\n",
      "  -0.33438274  0.46084085 -0.0993834  -0.05190775 -0.47431722 -0.13947901\n",
      "   0.82848215  0.23790517  0.14562188 -0.37822253 -0.47614637  0.02395292]\n",
      " [ 0.24137284 -0.13410679 -0.2657388  -0.15241846 -0.526012   -0.34691936\n",
      "   0.29360372  0.20801243  0.00923621  0.19353239  0.28984752  0.25090322\n",
      "   0.32246172 -0.01913101  0.2900349   0.29199663  0.4970099   0.19507279\n",
      "   0.01010849 -0.27170956 -0.60679984  0.6602774  -0.09023096  0.13100898\n",
      "   0.0229098   0.14243406 -0.33306774 -0.10601613 -0.229969    0.28602266]\n",
      " [ 0.0490338  -0.679143    0.24793728  0.3651831   0.02567773  0.5219925\n",
      "  -0.19699165 -0.7377443   0.98342466  0.2065902   0.09231405  0.10266133\n",
      "   0.01713221  0.27492717 -0.33639467 -0.5209765   0.44228756 -0.35892323\n",
      "  -0.11999079 -0.62540716  0.6921615  -0.17087036 -0.45450014 -0.09700551\n",
      "  -0.35340244  0.05626447 -0.11299603 -0.12303968  0.09768161 -0.5627251 ]\n",
      " [ 0.45599788 -0.7397321   0.153738    0.2034252   0.40834793 -0.12784697\n",
      "  -0.4577425  -0.61881596 -0.02665848 -0.7553048   0.4832362   0.5138366\n",
      "   0.52064407 -0.6732789   0.51012963  0.15326385 -0.44308922 -0.0242762\n",
      "   0.440678   -0.05475683  0.39067945 -0.3007629   0.31560665  0.00472169\n",
      "   0.51517165  0.01196195  0.10550137 -0.3459236   0.35972652  0.5596905 ]\n",
      " [ 0.02429858  0.2922521  -0.24889396 -0.9057984  -0.14666095  0.20293894\n",
      "  -0.0218748   0.060035    0.18076937 -0.71218044  0.30761284  0.06014083\n",
      "   0.07615219 -0.6808175  -0.04306674  0.46530804  0.08621705 -0.65958446\n",
      "   0.193367    0.07802729 -0.06233689 -0.18406732 -0.8577973   0.0507378\n",
      "  -0.04111836 -0.2412629  -0.33600762  0.28278324 -0.65299064 -0.6072235 ]\n",
      " [ 0.19684833 -0.06929261  0.4403648  -0.67899704  0.40325308 -0.42645398\n",
      "   0.35423496 -0.16418393  0.45851722 -0.13631265 -0.24373336 -0.4039562\n",
      "   0.20407742  0.11659574 -0.1860308  -0.06125709  0.32953015 -0.17312786\n",
      "  -0.54799134  0.49732977  0.182349    0.47226182  0.6803181   0.53060377\n",
      "   0.33236417  0.21845272 -0.16273561  0.28630593  0.19850022  0.3657021 ]\n",
      " [-0.12497848 -0.640306   -0.34859645 -0.739389    0.20314988 -0.03630476\n",
      "   0.20747748  0.39169145  0.53448826 -0.02521034 -0.05546318 -0.32425115\n",
      "  -0.16552798  0.43962204  1.0551722  -0.63859725 -0.3375972  -0.56226563\n",
      "   0.02597737 -0.3202055   0.27618957 -0.0225914  -0.3311626   0.6043406\n",
      "   0.22861193  0.0018169   0.5859362   0.26246965  0.5175719   0.26954854]\n",
      " [ 0.25327408  0.51089984  0.70609397  0.06349204  0.19050679  0.54970723\n",
      "  -0.00440303 -0.44641867 -0.5416019   0.6914638   0.2026637  -0.18963815\n",
      "   0.2823453   0.2640227   0.90759486  0.19156258  0.36418855 -0.25037494\n",
      "  -0.29332632 -0.05131147 -0.4846593   0.0107458   0.31850305  0.30629098\n",
      "   0.64187056 -0.27096814 -0.29269052  0.03745858 -0.01979387 -0.11732866]]\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MOFA(nn.Module):\n",
    "    def __init__(self, num_samples, num_features1, num_features2, num_factors):\n",
    "        super(MOFA, self).__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.num_features1 = num_features1\n",
    "        self.num_features2 = num_features2\n",
    "        self.num_factors = num_factors\n",
    "        \n",
    "        # Initialize shared latent factors\n",
    "        self.S = nn.Parameter(torch.randn(num_samples, num_factors) * 0.01)\n",
    "        \n",
    "        # Initialize private latent factors for each view\n",
    "        self.U1 = nn.Parameter(torch.randn(num_factors, num_features1) * 0.01)\n",
    "        self.U2 = nn.Parameter(torch.randn(num_factors, num_features2) * 0.01)\n",
    "\n",
    "    def model(self, X1, X2):\n",
    "        # Priors\n",
    "        S_prior = dist.Normal(torch.zeros(self.num_samples, self.num_factors), torch.ones(self.num_samples, self.num_factors)).to_event(2)\n",
    "        U1_prior = dist.Normal(torch.zeros(self.num_factors, self.num_features1), torch.ones(self.num_factors, self.num_features1)).to_event(2)\n",
    "        U2_prior = dist.Normal(torch.zeros(self.num_factors, self.num_features2), torch.ones(self.num_factors, self.num_features2)).to_event(2)\n",
    "        \n",
    "        # Sample from priors\n",
    "        S = pyro.sample('S', S_prior)\n",
    "        U1 = pyro.sample('U1', U1_prior)\n",
    "        U2 = pyro.sample('U2', U2_prior)\n",
    "        \n",
    "        # Likelihood\n",
    "        X1_hat = torch.matmul(S, U1)\n",
    "        X2_hat = torch.matmul(S, U2)\n",
    "        \n",
    "        with pyro.plate('data1', X1.shape[0]):\n",
    "            pyro.sample('obs1', dist.Normal(X1_hat, 0.1).to_event(1), obs=X1)\n",
    "        \n",
    "        with pyro.plate('data2', X2.shape[0]):\n",
    "            pyro.sample('obs2', dist.Normal(X2_hat, 0.1).to_event(1), obs=X2)\n",
    "\n",
    "    def guide(self, X1, X2):\n",
    "        # Variational distributions\n",
    "        S_loc = pyro.param('S_loc', torch.randn(self.num_samples, self.num_factors) * 0.01)\n",
    "        S_scale = pyro.param('S_scale', torch.ones(self.num_samples, self.num_factors) * 0.1, constraint=dist.constraints.positive)\n",
    "        U1_loc = pyro.param('U1_loc', torch.randn(self.num_factors, self.num_features1) * 0.01)\n",
    "        U1_scale = pyro.param('U1_scale', torch.ones(self.num_factors, self.num_features1) * 0.1, constraint=dist.constraints.positive)\n",
    "        U2_loc = pyro.param('U2_loc', torch.randn(self.num_factors, self.num_features2) * 0.01)\n",
    "        U2_scale = pyro.param('U2_scale', torch.ones(self.num_factors, self.num_features2) * 0.1, constraint=dist.constraints.positive)\n",
    "        \n",
    "        S_dist = dist.Normal(S_loc, S_scale).to_event(2)\n",
    "        U1_dist = dist.Normal(U1_loc, U1_scale).to_event(2)\n",
    "        U2_dist = dist.Normal(U2_loc, U2_scale).to_event(2)\n",
    "        \n",
    "        pyro.sample('S', S_dist)\n",
    "        pyro.sample('U1', U1_dist)\n",
    "        pyro.sample('U2', U2_dist)\n",
    "\n",
    "# Example usage:\n",
    "num_samples2 = 100\n",
    "num_samples = 80\n",
    "num_features1 = 20\n",
    "num_features2 = 30\n",
    "num_factors = 10\n",
    "num_iterations = 2000\n",
    "\n",
    "# Generate synthetic data\n",
    "X1 = torch.randn(num_samples2, num_features1)\n",
    "X2 = torch.randn(num_samples2, num_features2)\n",
    "\n",
    "X1_train = X1[:num_samples]\n",
    "X2_train = X2[:num_samples]\n",
    "X1_val = X1[num_samples:]\n",
    "X2_val = X2[num_samples:]\n",
    "\n",
    "# Initialize the model\n",
    "model = MOFA(num_samples, num_features1, num_features2, num_factors)\n",
    "\n",
    "# Setup the optimizer and the inference algorithm\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model.model, model.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Train the model and log loss\n",
    "losses = []\n",
    "val_losses = []\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(X1_train, X2_train)\n",
    "    losses.append(loss)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i} : loss = {loss:.4f}\")\n",
    "# Plot the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "# Get the learned latent factors\n",
    "S_posterior = pyro.param(\"S_loc\").detach().numpy()\n",
    "U1_posterior = pyro.param(\"U1_loc\").detach().numpy()\n",
    "U2_posterior = pyro.param(\"U2_loc\").detach().numpy()\n",
    "\n",
    "print(\"Shared components (S):\\n\", S_posterior)\n",
    "print(\"\\nPrivate components for view 1 (U1):\\n\", U1_posterior)\n",
    "print(\"\\nPrivate components for view 2 (U2):\\n\", U2_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (80) at non-singleton dimension 0\nTrace Shapes:          \n Param Sites:          \n      S_scale    100 10\n     U1_scale     10 20\n     U2_scale     10 30\nSample Sites:          \n  U1_loc dist 20  10  |\n        value 20  10  |\n  U2_loc dist 30  10  |\n        value 30  10  |\n   S_loc dist 80  10  |\n        value 80  10  |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:191\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m, in \u001b[0;36mMOFA.guide\u001b[0;34m(self, X1, X2)\u001b[0m\n\u001b[1;32m     88\u001b[0m U2_scale \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39mparam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU2_scale\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_factors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m, constraint\u001b[38;5;241m=\u001b[39mdist\u001b[38;5;241m.\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mpositive)\n\u001b[0;32m---> 90\u001b[0m S_dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_loc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m U1_dist \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mGamma(U1_scale, U1_loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/distributions/distribution.py:26\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/gamma.py:53\u001b[0m, in \u001b[0;36mGamma.__init__\u001b[0;34m(self, concentration, rate, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, concentration, rate, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcentration, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcentration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(concentration, Number) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rate, Number):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/utils.py:53\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (80) at non-singleton dimension 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Validation step\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/enum.py:60\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     58\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m unwrapped_guide\u001b[38;5;241m.\u001b[39mget_traces()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[38;5;241m.\u001b[39mdetach_()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:216\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Trace:\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    197\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 198\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39mret\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:191\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    193\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m, in \u001b[0;36mMOFA.guide\u001b[0;34m(self, X1, X2)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#U2_loc = pyro.param('U2_loc', torch.randn(self.num_factors, self.num_features2) * 0.01)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m U2_scale \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39mparam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU2_scale\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_factors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m, constraint\u001b[38;5;241m=\u001b[39mdist\u001b[38;5;241m.\u001b[39mconstraints\u001b[38;5;241m.\u001b[39mpositive)\n\u001b[0;32m---> 90\u001b[0m S_dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_loc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m U1_dist \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mGamma(U1_scale, U1_loc)\n\u001b[1;32m     92\u001b[0m U2_dist \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mGamma(U2_scale, U2_loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/distributions/distribution.py:26\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/gamma.py:53\u001b[0m, in \u001b[0;36mGamma.__init__\u001b[0;34m(self, concentration, rate, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, concentration, rate, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcentration, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcentration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(concentration, Number) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rate, Number):\n\u001b[1;32m     55\u001b[0m         batch_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/utils.py:53\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     49\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     50\u001b[0m         v \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(v) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values\n\u001b[1;32m     51\u001b[0m     ]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (80) at non-singleton dimension 0\nTrace Shapes:          \n Param Sites:          \n      S_scale    100 10\n     U1_scale     10 20\n     U2_scale     10 30\nSample Sites:          \n  U1_loc dist 20  10  |\n        value 20  10  |\n  U2_loc dist 30  10  |\n        value 30  10  |\n   S_loc dist 80  10  |\n        value 80  10  |"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MOFA(nn.Module):\n",
    "    def __init__(self, training_size, num_features1, num_features2, num_factors):\n",
    "        super(MOFA, self).__init__()\n",
    "        self.training_size = training_size\n",
    "        self.num_features1 = num_features1\n",
    "        self.num_features2 = num_features2\n",
    "        self.num_factors = num_factors\n",
    "\n",
    "        self.sample_plate = pyro.plate(\"sample\", 80)\n",
    "        self.feature_plate1 = pyro.plate(\"feature1\", num_features1)\n",
    "        self.feature_plate2 = pyro.plate(\"feature2\", num_features2)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", num_factors)\n",
    "\n",
    "    def model(self, X1, X2):\n",
    "        \n",
    "        num_samples = X1.shape[0]  # Update num_samples based on the current batch size\n",
    "        print(f\"num_samples:{self.training_size}\")\n",
    "        # Priors\n",
    "        print(f\"feature_plate1:{self.feature_plate1}\")\n",
    "        #print(f\"feature_plate2:{self.feature_plate2.shape}\")\n",
    "        #print(f\"sample_plate:{self.sample_plate.shape}\")\n",
    "        #print(f\"latent_factor:{self.latent_factor_plate.shape}\")\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate1:\n",
    "                U1 = pyro.sample(\"U1\", pyro.distributions.Normal(0., 1.))\n",
    "            with self.feature_plate2:\n",
    "                U2 = pyro.sample(\"U2\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        with self.latent_factor_plate:\n",
    "            with self.sample_plate:\n",
    "                S = pyro.sample(\"S\", pyro.distributions.Normal(0., 1.))\n",
    "        print(f\"S.shape: {S.shape}\")\n",
    "\n",
    "        #S_prior = dist.MultivariateNormal(torch.zeros(self.num_samples, self.num_factors), torch.ones(self.num_samples, self.num_factors))\n",
    "        #U1_prior = dist.MultivariateNormal(torch.zeros(self.num_factors, self.num_features1), torch.ones(self.num_factors, self.num_features1))\n",
    "        #U2_prior = dist.MultivariateNormal(torch.zeros(self.num_factors, self.num_features2), torch.ones(self.num_factors, self.num_features2))\n",
    "        \n",
    "        # Sample from priors\n",
    "        #S = pyro.sample('S', S_prior)\n",
    "        #print(f\"S.shape: {S.shape}, S_prior.shape: {S_prior.shape}\")\n",
    "        #U1 = pyro.sample('U1', U1_prior)\n",
    "        #U2 = pyro.sample('U2', U2_prior)\n",
    "        #print(f\"U1.shape: {U1.shape}, U1_prior.shape: {U1_prior.shape}\")\n",
    "        #print(f\"U2.shape: {U2.shape}, U2_prior.shape: {U2_prior.shape}\")\n",
    "\n",
    "        # Likelihood\n",
    "        X1_hat = torch.matmul(S.T, U1)\n",
    "        X2_hat = torch.matmul(S.T, U2)\n",
    "\n",
    "        # Debugging: print shapes\n",
    "        print(f\"X1.shape: {X1.shape}, X1_hat.shape: {X1_hat.shape}\")\n",
    "        print(f\"X2.shape: {X2.shape}, X2_hat.shape: {X2_hat.shape}\")\n",
    "        \n",
    "        with pyro.plate('data1', X1.shape[0]):\n",
    "            pyro.sample('obs1', dist.Normal(X1_hat, 0.1).to_event(1), obs=X1)\n",
    "        \n",
    "        with pyro.plate('data2', X2.shape[0]):\n",
    "            pyro.sample('obs2', dist.Normal(X2_hat, 0.1).to_event(1), obs=X2)\n",
    "\n",
    "    def guide(self, X1, X2):\n",
    "        num_samples = X1.shape[0]  # Update num_samples based on the current batch size\n",
    "\n",
    "        # Variational distributions\n",
    "\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate1:\n",
    "                U1_loc = pyro.sample(\"U1_loc\", pyro.distributions.Normal(0., 1.))\n",
    "            with self.feature_plate2:\n",
    "                U2_loc = pyro.sample(\"U2_loc\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        with self.latent_factor_plate:\n",
    "            with self.sample_plate:\n",
    "                S_loc = pyro.sample(\"S_loc\", pyro.distributions.Normal(0., 1.))\n",
    "\n",
    "        #S_loc = pyro.param('S_loc', torch.randn(num_samples, self.num_factors) * 0.01)\n",
    "        S_scale = pyro.param('S_scale', torch.ones(num_samples, self.num_factors) * 0.1, constraint=dist.constraints.positive)\n",
    "        #U1_loc = pyro.param('U1_loc', torch.randn(self.num_factors, self.num_features1) * 0.01)\n",
    "        U1_scale = pyro.param('U1_scale', torch.ones(self.num_factors, self.num_features1) * 0.1, constraint=dist.constraints.positive)\n",
    "        #U2_loc = pyro.param('U2_loc', torch.randn(self.num_factors, self.num_features2) * 0.01)\n",
    "        U2_scale = pyro.param('U2_scale', torch.ones(self.num_factors, self.num_features2) * 0.1, constraint=dist.constraints.positive)\n",
    "        \n",
    "        S_dist = dist.Gamma(S_scale, S_loc)\n",
    "        U1_dist = dist.Gamma(U1_scale, U1_loc)\n",
    "        U2_dist = dist.Gamma(U2_scale, U2_loc)\n",
    "        \n",
    "        pyro.sample('S', S_dist)\n",
    "        pyro.sample('U1', U1_dist)\n",
    "        pyro.sample('U2', U2_dist)\n",
    "\n",
    "# Example usage:\n",
    "num_samples = 100\n",
    "num_features1 = 20\n",
    "num_features2 = 30\n",
    "num_factors = 10\n",
    "num_iterations = 2000\n",
    "\n",
    "# Generate synthetic data\n",
    "X1 = torch.randn(num_samples, num_features1)\n",
    "X2 = torch.randn(num_samples, num_features2)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_size = int(0.8 * num_samples)\n",
    "X1_train = X1[:,:train_size]\n",
    "X2_train = X2[:,:train_size]\n",
    "X1_val = X1[:,train_size:]\n",
    "X2_val = X2[:,train_size:]\n",
    "\n",
    "# Initialize the model with training set size\n",
    "model = MOFA(train_size, num_features1, num_features2, num_factors)\n",
    "\n",
    "# Setup the optimizer and the inference algorithm\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model.model, model.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Training loop with validation loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for i in range(num_iterations):\n",
    "    # Training step\n",
    "    train_loss = svi.step(X1_train, X2_train)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation step\n",
    "    with torch.no_grad():\n",
    "        val_loss = svi.evaluate_loss(X1_val, X2_val)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Print losses every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i} : train loss = {train_loss:.4f}, val loss = {val_loss:.4f}\")\n",
    "\n",
    "# Plot the training and validation loss curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Get the learned latent factors\n",
    "S_posterior = pyro.param(\"S_loc\").detach().numpy()\n",
    "U1_posterior = pyro.param(\"U1_loc\").detach().numpy()\n",
    "U2_posterior = pyro.param(\"U2_loc\").detach().numpy()\n",
    "\n",
    "print(\"Shared components (S):\\n\", S_posterior)\n",
    "print(\"\\nPrivate components for view 1 (U1):\\n\", U1_posterior)\n",
    "print(\"\\nPrivate components for view 2 (U2):\\n\", U2_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FA(PyroModule):\n",
    "    def __init__(self, Y1, Y2, K):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y: Tensor (Samples x Features)\n",
    "            K: Number of Latent Factors\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        pyro.clear_param_store()\n",
    "        \n",
    "        # data\n",
    "        self.Y1 = Y1\n",
    "        self.Y2 = Y2\n",
    "        self.K = K\n",
    "        \n",
    "        self.num_samples = self.Y1.shape[0]\n",
    "        self.num_features1 = self.Y1.shape[1]\n",
    "        self.num_features2 = self.Y2.shape[1]\n",
    "        \n",
    "        self.sample_plate = pyro.plate(\"sample\", self.num_samples)\n",
    "        self.feature_plate1 = pyro.plate(\"feature1\", self.num_features1)\n",
    "        self.feature_plate2 = pyro.plate(\"feature2\", self.num_features2)\n",
    "        self.latent_factor_plate = pyro.plate(\"latent factors\", self.K)\n",
    "        \n",
    "        \n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        how to generate a matrix\n",
    "        \"\"\"\n",
    "        with self.latent_factor_plate:\n",
    "            with self.feature_plate1:\n",
    "                # sample weight matrix with Normal prior distribution\n",
    "                W1 = pyro.sample(\"W1\", pyro.distributions.Normal(0., 1.))\n",
    "            with self.feature_plate2:\n",
    "                W2 = pyro.sample(\"W2\", pyro.distributions.Normal(0., 1.))                \n",
    "                \n",
    "            with self.sample_plate:\n",
    "                # sample factor matrix with Normal prior distribution\n",
    "                Z = pyro.sample(\"Z\", pyro.distributions.Normal(0., 1.))\n",
    "        \n",
    "        # estimate for Y\n",
    "        Y1_hat = torch.matmul(Z, W1.t())\n",
    "        Y2_hat = torch.matmul(Z, W2.t())\n",
    "        \n",
    "        with pyro.plate(\"feature1_\", self.Y1.shape[1]), pyro.plate(\"sample1_\", self.Y1.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs1_mask = torch.ones_like(self.Y1, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs1_mask = torch.logical_not(torch.isnan(self.Y1))\n",
    "            with pyro.poutine.mask(mask=obs1_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y1 = torch.nan_to_num(self.Y1, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale1 = pyro.sample(\"scale1\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs1\", pyro.distributions.Normal(Y1_hat, scale1), obs=self.Y1)\n",
    "        \n",
    "        with pyro.plate(\"feature2_\", self.Y2.shape[1]), pyro.plate(\"sample2_\", self.Y2.shape[0]):\n",
    "            # masking the NA values such that they are not considered in the distributions\n",
    "            obs2_mask = torch.ones_like(self.Y2, dtype=torch.bool)\n",
    "            if data is not None:\n",
    "                obs2_mask = torch.logical_not(torch.isnan(self.Y2))\n",
    "            with pyro.poutine.mask(mask=obs2_mask):\n",
    "                if data is not None:\n",
    "                    # a valid value for the NAs has to be defined even though these samples will be ignored later\n",
    "                    self.Y2 = torch.nan_to_num(self.Y2, nan=0) \n",
    "            \n",
    "                    # sample scale parameter for each feature-sample pair with LogNormal prior (has to be positive)\n",
    "                    scale2 = pyro.sample(\"scale2\", pyro.distributions.LogNormal(0., 1.))\n",
    "                    # compare sampled estimation to the true observation Y\n",
    "                    pyro.sample(\"obs2\", pyro.distributions.Normal(Y2_hat, scale2), obs=self.Y2)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # set training parameters\n",
    "        optimizer = pyro.optim.Adam({\"lr\": 0.02})\n",
    "        elbo = Trace_ELBO()\n",
    "        guide = autoguide.AutoDelta(self.model)\n",
    "        \n",
    "        # initialize stochastic variational inference\n",
    "        svi = SVI(\n",
    "            model = self.model,\n",
    "            guide = guide,\n",
    "            optim = optimizer,\n",
    "            loss = elbo\n",
    "        )\n",
    "        \n",
    "        num_iterations = 2000\n",
    "        train_loss = []\n",
    "        val_losses = []\n",
    "        for j in range(num_iterations):\n",
    "            # calculate the loss and take a gradient step\n",
    "            #print(torch.cat((X1_train.T, X2_train.T), dim=0))\n",
    "            loss = svi.step()\n",
    "\n",
    "            train_loss.append(loss/self.Y1.shape[0])\n",
    "            with torch.no_grad():\n",
    "                val_loss = svi.evaluate_loss(X1_val, X2_val)\n",
    "                val_losses.append(val_loss)\n",
    "    \n",
    "            # Print losses every 100 iterations\n",
    "            if j % 100 == 0:\n",
    "                print(f\"Step {j} : train loss = {train_loss:.4f}, val loss = {val_loss:.4f}\")\n",
    "            #if j % 200 == 0:\n",
    "            #    print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / self.Y1.shape[0]))\n",
    "        \n",
    "        # Obtain maximum a posteriori estimates for W and Z\n",
    "        map_estimates = guide(Y1, Y2)\n",
    "        \n",
    "        return train_loss, map_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/.local/lib/python3.8/site-packages/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'feature1', 'sample', 'feature2', 'latent factors'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "model() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m X2_val \u001b[38;5;241m=\u001b[39m X2[:,train_size:]\n\u001b[1;32m     19\u001b[0m FA_model \u001b[38;5;241m=\u001b[39m FA(X1_train, X2_train,\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m losses, estimates \u001b[38;5;241m=\u001b[39m \u001b[43mFA_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 100\u001b[0m, in \u001b[0;36mFA.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 100\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Print losses every 100 iterations\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/svi.py:127\u001b[0m, in \u001b[0;36mSVI.evaluate_loss\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m:returns: estimate of the loss\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m:rtype: float\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mEvaluate the loss function. Any args or kwargs are passed to the model and guide.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 127\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# Support losses that return a tuple, e.g. ReweightedWakeSleep.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(loss)(\u001b[38;5;28mmap\u001b[39m(torch_item, loss))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:72\u001b[0m, in \u001b[0;36mTrace_ELBO.loss\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m:returns: returns an estimate of the ELBO\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m:rtype: float\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mEvaluates the ELBO with an estimator that uses num_particles many samples/particles.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m     73\u001b[0m     elbo_particle \u001b[38;5;241m=\u001b[39m torch_item(model_trace\u001b[38;5;241m.\u001b[39mlog_prob_sum()) \u001b[38;5;241m-\u001b[39m torch_item(\n\u001b[1;32m     74\u001b[0m         guide_trace\u001b[38;5;241m.\u001b[39mlog_prob_sum()\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m     elbo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elbo_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mget_importance_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/infer/enum.py:65\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[0;32m---> 65\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguide_trace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_type\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     70\u001b[0m     check_model_guide_match(model_trace, guide_trace, max_plate_nesting)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:216\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Trace:\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py:191\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    193\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyro/poutine/messenger.py:32\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(\n\u001b[1;32m     26\u001b[0m     context: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     fn: Callable,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: model() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "num_features1 = 20\n",
    "num_features2 = 20\n",
    "num_factors = 10\n",
    "num_iterations = 2000\n",
    "\n",
    "# Generate synthetic data\n",
    "X1 = torch.randn(num_samples, num_features1)\n",
    "X2 = torch.randn(num_samples, num_features2)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_size = int(0.8 * num_samples)\n",
    "X1_train = X1[:,:train_size]\n",
    "X2_train = X2[:,:train_size]\n",
    "X1_val = X1[:,train_size:]\n",
    "X2_val = X2[:,train_size:]\n",
    "\n",
    "\n",
    "FA_model = FA(X1_train, X2_train,10)\n",
    "losses, estimates = FA_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1911, -0.7829,  0.3724,  ...,  0.7869, -0.7921,  0.3925],\n",
       "        [ 1.0133,  0.4645,  0.2023,  ..., -0.2167,  0.6153, -0.0137],\n",
       "        [-0.3000,  0.6149, -0.3839,  ..., -0.9911, -0.3520, -0.9197],\n",
       "        ...,\n",
       "        [-0.6997, -0.9290,  0.9005,  ..., -0.9129, -0.8621,  1.3675],\n",
       "        [-1.4562,  0.1489, -1.5442,  ...,  0.1230,  1.2073, -0.8714],\n",
       "        [ 1.1323,  0.6291,  1.0210,  ...,  0.7032,  0.2642,  0.3194]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((X1_train.T, X2_train.T), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
